{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mangalm96/explainablenlp-info259/blob/main/train1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyEizW0NPJVc",
        "outputId": "f78b6722-a1f5-4c5a-bca2-042f022f2f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-_EYEUkPMpX",
        "outputId": "aaf4ee53-dc1d-4ffb-f80f-0aedd5682fc2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "data = open(\"/content/gdrive/MyDrive/NLP Stance Detection/Code_Kaushal/data/wtwt/data.json\")\n",
        "data_list = json.load(data)"
      ],
      "metadata": {
        "id": "9C83n8RAbarx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stance_dict = dict()\n",
        "for record in data_list:\n",
        "  stance = record[\"stance\"]\n",
        "  stance_dict[stance] = stance_dict.get(stance, 0) + 1"
      ],
      "metadata": {
        "id": "aE6DodHacD7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stance_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRxk-BMCcUk-",
        "outputId": "8c047f92-3e3e-426f-df92-32f19854b1bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'comment': 18087, 'refute': 3791, 'support': 5951, 'unrelated': 16169}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking traintest dev json\n",
        "train_dt = open(\"/content/gdrive/MyDrive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CI_ESRX_target/train.json\")\n",
        "train_dt_list = json.load(train_dt)\n"
      ],
      "metadata": {
        "id": "8c4AiJZpfBd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dt_list['data'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imDlVBprgMuO",
        "outputId": "942f5f7c-618b-464f-fbb2-b52289205d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27130"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targ_dict_tr = dict()\n",
        "for record in train_dt_list['data']:\n",
        "  stance = record[\"merger\"]\n",
        "  targ_dict_tr[stance] = targ_dict_tr.get(stance, 0) + 1"
      ],
      "metadata": {
        "id": "jUIBvXysfRom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targ_dict_tr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ra1gUFWgk-F",
        "outputId": "202739c3-efc5-4f2d-e257-bd653cdb6ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AET_HUM': 6996, 'ANTM_CI': 9927, 'CVS_AET': 10207}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking traintest dev json\n",
        "train_dt = open(\"/content/gdrive/MyDrive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CVS_AET_target/train.json\")\n",
        "train_dt_list = json.load(train_dt)\n",
        "\n",
        "targ_dict_tr = dict()\n",
        "for record in train_dt_list['data']:\n",
        "  stance = record[\"merger\"]\n",
        "  targ_dict_tr[stance] = targ_dict_tr.get(stance, 0) + 1\n",
        "\n",
        "targ_dict_tr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh6nPC1IhSgQ",
        "outputId": "82c9fda8-6a99-4440-e2d5-3064ea69d943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AET_HUM': 6996, 'ANTM_CI': 6094, 'CI_ESRX': 2226}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking traintest dev json\n",
        "train_dt = open(\"/content/gdrive/MyDrive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CI_ESRX_target/test.json\")\n",
        "train_dt_list = json.load(train_dt)\n",
        "\n",
        "targ_dict_tr = dict()\n",
        "for record in train_dt_list['data']:\n",
        "  stance = record[\"merger\"]\n",
        "  targ_dict_tr[stance] = targ_dict_tr.get(stance, 0) + 1\n",
        "\n",
        "targ_dict_tr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOjQdrVVhcaS",
        "outputId": "5a476c4f-6c8d-4249-c839-7276cfee4c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CI_ESRX': 2226}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CVS_AET_dict=dict()\n",
        "CI_ESRX_dict = dict()\n",
        "ANTM_CI_dict = dict()\n",
        "AET_HUM_dict = dict()\n",
        "DIS_FOXA_dict = dict()\n",
        "for record in data_list:\n",
        "  stance = record[\"stance\"]\n",
        "  merger = record[\"merger\"]\n",
        "  if merger == 'CVS_AET':\n",
        "    CVS_AET_dict[stance] = CVS_AET_dict.get(stance, 0) + 1\n",
        "  elif merger == 'CI_ESRX':\n",
        "    CI_ESRX_dict[stance] = CI_ESRX_dict.get(stance, 0) + 1\n",
        "  elif merger == 'ANTM_CI':\n",
        "    ANTM_CI_dict[stance] = ANTM_CI_dict.get(stance, 0) + 1\n",
        "  elif merger == 'AET_HUM':\n",
        "    AET_HUM_dict[stance] = AET_HUM_dict.get(stance, 0) + 1\n",
        "  else:\n",
        "    DIS_FOXA_dict[stance] = DIS_FOXA_dict.get(stance, 0) + 1\n"
      ],
      "metadata": {
        "id": "Qj3FVrLDlzMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(CVS_AET_dict)\n",
        "print(CI_ESRX_dict)\n",
        "print(ANTM_CI_dict)\n",
        "print(AET_HUM_dict)\n",
        "print(DIS_FOXA_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY4_HsKKoKk7",
        "outputId": "40613550-b091-45ad-b3eb-5cca25610620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'support': 2225, 'comment': 4899, 'unrelated': 2636, 'refute': 447}\n",
            "{'support': 688, 'unrelated': 461, 'comment': 852, 'refute': 225}\n",
            "{'support': 881, 'unrelated': 4444, 'comment': 2811, 'refute': 1791}\n",
            "{'support': 937, 'comment': 2538, 'unrelated': 2523, 'refute': 998}\n",
            "{'comment': 6987, 'unrelated': 6105, 'support': 1220, 'refute': 330}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## installs and imports"
      ],
      "metadata": {
        "id": "k48T2Vi4o3SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==3.5.0\n",
        "!pip install wandb==0.9.4\n",
        "!pip install scikit-learn==0.23.1\n",
        "!pip install scipy==1.5.0\n",
        "!pip install ekphrasis==0.5.1\n",
        "!pip install emoji\n",
        "import time"
      ],
      "metadata": {
        "id": "x6tCpuzVPWLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129f7be5-3218-448c-d155-badff265eabd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.5.0\n",
            "  Downloading transformers-3.5.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 36.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (1.21.5)\n",
            "Collecting tokenizers==0.9.3\n",
            "  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 33.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.0) (3.0.7)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.0) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (7.1.2)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.49 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.0\n",
            "Collecting wandb==0.9.4\n",
            "  Downloading wandb-0.9.4-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (3.13)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (7.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (1.15.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (7.352.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting gql==0.2.0\n",
            "  Downloading gql-0.2.0.tar.gz (18 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (2.23.0)\n",
            "Collecting watchdog>=0.8.3\n",
            "  Downloading watchdog-2.1.7-py3-none-manylinux2014_x86_64.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (2.8.2)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "  Downloading sentry_sdk-1.5.8-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 46.8 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 45.2 MB/s \n",
            "\u001b[?25hCollecting graphql-core<2,>=0.5.0\n",
            "  Downloading graphql-core-1.1.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from gql==0.2.0->wandb==0.9.4) (2.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb==0.9.4) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (2021.10.8)\n",
            "Building wheels for collected packages: gql, graphql-core, subprocess32\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-py3-none-any.whl size=7638 sha256=c540cedeac2bb985f42fa6fc1b3db48307fc6b1d69ba2790add7b869c51b137e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/9a/56/5456fd32264a8fc53eefcb2f74e24e99a7ef4eb40a9af5c905\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-py3-none-any.whl size=104649 sha256=5c71ff24dfb6c8110d4c2b2eb9a1d13734b46f2c67250de0c74e503451ef29e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/fd/8c/a20dd591c1a554070cc33fb58042867e6ac1c85395abe2e57a\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=401634363811cd95c390fc191d4c493f35b5946d056c11613f44f9522ab34b53\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "Successfully built gql graphql-core subprocess32\n",
            "Installing collected packages: smmap, graphql-core, gitdb, watchdog, subprocess32, shortuuid, sentry-sdk, gql, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.27 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 gql-0.2.0 graphql-core-1.1 sentry-sdk-1.5.8 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.9.4 watchdog-2.1.7\n",
            "Collecting scikit-learn==0.23.1\n",
            "  Downloading scikit_learn-0.23.1-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (1.4.1)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.1 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.1\n",
            "Collecting scipy==1.5.0\n",
            "  Downloading scipy-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.5.0) (1.21.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.5.0\n",
            "Collecting ekphrasis==0.5.1\n",
            "  Downloading ekphrasis-0.5.1.tar.gz (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (4.63.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting ujson\n",
            "  Downloading ujson-5.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (3.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (3.2.5)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (1.21.5)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis==0.5.1) (0.2.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->ekphrasis==0.5.1) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->ekphrasis==0.5.1) (1.15.0)\n",
            "Building wheels for collected packages: ekphrasis\n",
            "  Building wheel for ekphrasis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ekphrasis: filename=ekphrasis-0.5.1-py3-none-any.whl size=82842 sha256=c36585aab00ba5a87566f237498ee41574b7c911cb4b071182e5b2bfe3209637\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/ec/0d/12659e32faf780546945d0120f2c8410eb3efb7426731da88f\n",
            "Successfully built ekphrasis\n",
            "Installing collected packages: ujson, ftfy, colorama, ekphrasis\n",
            "Successfully installed colorama-0.4.4 ekphrasis-0.5.1 ftfy-6.1.1 ujson-5.2.0\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=731c10337bd8e03229cf49db9b303c1f7aad98bd82859b6fe6e42cee10f38fb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31CqjrIYbGEt",
        "outputId": "2eb2866e-edcb-46f9-edcc-f7c2185b3c8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 6.9 kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automated run"
      ],
      "metadata": {
        "id": "ZhKFpeT30rW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gdrive/My\\ Drive/NLP\\ Project/bias-stance/bertloader.py --target_merger=CI_ESRX --bert_type=vinai/bertweet-base --dataset_name=wtwt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRjwnQYXneXq",
        "outputId": "d5a43347-a3ed-49be-d33c-ca0f397e0178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = True\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 27130 0 2226\n",
            "Length of train, eval_set: 27130 2226\n",
            "Before shuffling train[0] =  944165633889095681 | After shuffling train[0] =  831878268378816513\n",
            "/content/gdrive/.shortcut-targets-by-id/1cqRKadLOmUTbjUjku8ixQublzk8n8F2_/NLP Project/bias-stance/saves/wtwt_CI_ESRX_target\n",
            "1. Type of train dataset\n",
            "27130\n",
            "{'tweet_id': '831878268378816513', 'merger': 'ANTM_CI', 'stance': 'support', 'text': ['Anthem', 'Sues', 'Cigna', 'To', 'Prevent', 'Termination', 'Of', 'Their', '$', '<number>', 'Billion', 'Dollar', 'Merger', 'Deal', 'anthem', 'cigna', 'merger', 'reuters'], 'target': 'Anthem Cigna'}\n",
            "Downloading: 100% 558/558 [00:00<00:00, 437kB/s]\n",
            "Downloading: 100% 843k/843k [00:00<00:00, 926kB/s]\n",
            "Downloading: 100% 1.08M/1.08M [00:01<00:00, 992kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1696  | num_data= 27130\n",
            "97\n",
            "Eval_dataset: num_batches= 140  | num_data= 2226\n",
            "97\n",
            "Train_dataset Size = 1696 Eval_dataset Size = 140\n",
            "1696\n",
            "(tensor([[    0, 22250,     3, 12691,     4,  2993,  2336,   144, 22250,   144,\n",
            "             3,   144,     3,   144,  7444, 22250, 13606,  9492,  7761,     2,\n",
            "             2, 17336, 42182,   880,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,     3,  9568,  1163,  5061,   633,    52,  4978,  4749,     9,\n",
            "         17336,  2993,     3,  7051,  4521,     2,     2, 17336, 42182,   880,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0, 12421, 55119,   708,  2047,  8536, 14659,     3,     7,     3,\n",
            "             7,     3,     2,     2,   327,  1828,   880,  7110,  1706,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,     3,  5763, 57274,   348,   619,   490, 17336, 33494, 10523,\n",
            "            22,   104,     3, 22507,   152,    31,    11,    26, 12446,  1278,\n",
            "            19,  2351,     4,     2,     2,   327,  1828,   880,  7110,  1706,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,   125,     3,    55, 17336,    32, 29541,     7,    11,  1330,\n",
            "            34,     3,    15,     3,  6797,     9, 17336,    34,   927,  9984,\n",
            "          7789, 23538,  4918,   144,   144,     2,     2, 17336, 42182,   880,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,   196,    64,     8,   307,     8,   152,    46,    26,  2784,\n",
            "            21,    26,   695,     7, 29769, 10473,     3,     2,     2, 38424,\n",
            "         24517,  1960,   327,  1828,   880,     2,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,   122,   144, 64001,    16,     3,    24,    66,     3,   144,\n",
            "         54266,   151,    32,    16,     6,   960,    15,     3,   144, 29769,\n",
            "             3,   144,     3,     3,     2,     2, 38424, 24517,  1960,   327,\n",
            "          1828,   880,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,   165,   158,     6,   127, 17336,    13, 29769,     3,   810,\n",
            "           271,    19,     3,    21,     2,     2, 38424, 24517,  1960,   327,\n",
            "          1828,   880,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,   295, 12873,   317,    22,     8,    43,     9,  2650,    18,\n",
            "             7,  2650,    18,    12,   295,  6347,   317,    22,     8,    43,\n",
            "             9,   560,    18,     7,   560,    18,    12,   295, 22716,   317,\n",
            "            22,     8,    43,     9, 29541,    18,     7, 29541,    18,    12,\n",
            "           295, 16203,   317,    22,  1418,   361, 64001,     2,     2, 17336,\n",
            "         42182,   880,     2],\n",
            "        [    0,  2780,  2116,    70, 12446,  4127,  4783,    19, 17336,     4,\n",
            "         17336,    34,     3, 23536,  4647,     9,   297,   217,   223,     2,\n",
            "             2, 17336, 42182,   880,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1]], device='cuda:0'), tensor([1, 3, 1, 0, 0, 2, 0, 1, 1, 0], device='cuda:0'), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'))\n",
            "Sun Apr 10 00:05:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    59W / 149W |    347MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gdrive/My\\ Drive/NLP\\ Project/bias-stance/train.py --dataset_name=wtwt --target_merger=CI_ESRX --test_mode=True --bert_type=vinai/bertweet-base"
      ],
      "metadata": {
        "id": "F9Wk-jYCPRlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python gdrive/My\\ Drive/NLP\\ Project/bias-stance/train.py --dataset_name=wtwt --target_merger=CI_ESRX --test_mode=True --bert_type=vinai/bertweet-base --notarget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyGwQo0v61HO",
        "outputId": "b136a55f-ac45-4b66-a87b-8452fb0b16d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = False\n",
            "++++++++++++++++++++++\n",
            "Traceback (most recent call last):\n",
            "  File \"gdrive/My Drive/NLP Project/bias-stance/train.py\", line 8, in <module>\n",
            "  File \"/content/gdrive/.shortcut-targets-by-id/1cqRKadLOmUTbjUjku8ixQublzk8n8F2_/NLP Project/bias-stance/bertloader.py\", line 5, in <module>\n",
            "    from transformers import AutoTokenizer\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/__init__.py\", line 22, in <module>\n",
            "    from .integrations import (  # isort:skip\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/integrations.py\", line 81, in <module>\n",
            "    from .file_utils import is_torch_tpu_available  # noqa: E402\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\", line 59, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 51, in <module>\n",
            "    from ._api.v2 import compat\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/__init__.py\", line 37, in <module>\n",
            "    from . import v1\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 30, in <module>\n",
            "    from . import compat\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 37, in <module>\n",
            "    from . import v1\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\", line 47, in <module>\n",
            "    from tensorflow._api.v2.compat.v1 import lite\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py\", line 9, in <module>\n",
            "    from . import experimental\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py\", line 8, in <module>\n",
            "    from . import authoring\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.lite.python.authoring.authoring import compatible\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/authoring/authoring.py\", line 43, in <module>\n",
            "    from tensorflow.lite.python import convert\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py\", line 29, in <module>\n",
            "    from tensorflow.lite.python import util\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/util.py\", line 51, in <module>\n",
            "    from jax import xla_computation as _xla_computation\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/__init__.py\", line 135, in <module>\n",
            "    from jax import nn as nn\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/nn/__init__.py\", line 21, in <module>\n",
            "    from jax._src.nn.functions import (\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/nn/functions.py\", line 29, in <module>\n",
            "    from jax.scipy.special import expit\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/scipy/__init__.py\", line 19, in <module>\n",
            "    from jax.scipy import signal as signal\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/scipy/signal.py\", line 17, in <module>\n",
            "    from jax._src.scipy.signal import (\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/scipy/signal.py\", line 15, in <module>\n",
            "    import scipy.signal as osp_signal\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/signal/__init__.py\", line 307, in <module>\n",
            "    from ._peak_finding import *\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/signal/_peak_finding.py\", line 8, in <module>\n",
            "    from scipy.stats import scoreatpercentile\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/__init__.py\", line 388, in <module>\n",
            "    from .stats import *\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py\", line 180, in <module>\n",
            "    from . import distributions\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/distributions.py\", line 12, in <module>\n",
            "    from . import _discrete_distns\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/_discrete_distns.py\", line 703, in <module>\n",
            "    planck = planck_gen(a=0, name='planck', longname='A discrete exponential ')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/_distn_infrastructure.py\", line 2880, in __init__\n",
            "    locscale_out='loc, 1')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/_distn_infrastructure.py\", line 701, in _construct_argparser\n",
            "    exec(parse_arg_template % dct, ns)\n",
            "  File \"<string>\", line 2, in <module>\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "byrwwrQA2vaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## individual script run"
      ],
      "metadata": {
        "id": "zgb8EqJGy0AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# target_merger=['CVS_AET', 'ANTM_CI', 'AET_HUM', 'CI_ESRX']"
      ],
      "metadata": {
        "id": "-fDB-gVTqy8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CVS_AET"
      ],
      "metadata": {
        "id": "zOhwtfGlo9en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='CVS_AET' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=5 --lr=1e-5\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdqK-rby0tkN",
        "outputId": "f70ea27b-bcf2-4d77-da1a-4ae46c8cfd1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = True\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 19149 0 10207\n",
            "Length of train, eval_set: 19149 10207\n",
            "Before shuffling train[0] =  971761970117357568 | After shuffling train[0] =  799735673758461952\n",
            "/content/gdrive/My Drive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CVS_AET_target\n",
            "1. Type of train dataset\n",
            "Length of train: 19149\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1197  | num_data= 19149\n",
            "88\n",
            "Eval_dataset: num_batches= 638  | num_data= 10207\n",
            "97\n",
            "Dataset created\n",
            "Mon Apr 11 05:26:01 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    60W / 149W |    345MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Model created\n",
            "Mon Apr 11 05:26:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    60W / 149W |    345MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 21.683727264404297\n",
            "Train loss at 100: 17.37588882446289\n",
            "Train loss at 200: 21.265077590942383\n",
            "Train loss at 300: 11.008048057556152\n",
            "Train loss at 400: 14.134414672851562\n",
            "Train loss at 500: 10.802080154418945\n",
            "Train loss at 600: 5.207605838775635\n",
            "Train loss at 700: 15.33102035522461\n",
            "Train loss at 800: 7.037755966186523\n",
            "Train loss at 900: 3.525812864303589\n",
            "Train loss at 1000: 3.9165823459625244\n",
            "Train loss at 1100: 10.071182250976562\n",
            "EVALUATING:\n",
            "Valid_loss 11.706643349324647\n",
            "[[3699  875  247   78]\n",
            " [ 784 1753   62   37]\n",
            " [ 475  163 1549   38]\n",
            " [ 183    9   10  245]]\n",
            "comment F1-score: 0.7368525896414342\n",
            "unrelated F1-score: 0.6449595290654893\n",
            "support F1-score: 0.7569020278524309\n",
            "refute F1-score: 0.5798816568047336\n",
            "Accu: 0.7099049671793867\n",
            "F1-Weighted 0.7106170537702939\n",
            "F1-Avg 0.679648950841022\n",
            "[0/5]     train_loss: 10.93724 valid_loss: 11.70664\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 5.605476379394531\n",
            "Train loss at 100: 6.825107574462891\n",
            "Train loss at 200: 15.43228530883789\n",
            "Train loss at 300: 5.038177967071533\n",
            "Train loss at 400: 8.456314086914062\n",
            "Train loss at 500: 10.147379875183105\n",
            "Train loss at 600: 4.010861396789551\n",
            "Train loss at 700: 14.042593002319336\n",
            "Train loss at 800: 4.708942413330078\n",
            "Train loss at 900: 1.6914137601852417\n",
            "Train loss at 1000: 2.179783344268799\n",
            "Train loss at 1100: 6.012068748474121\n",
            "EVALUATING:\n",
            "Valid_loss 12.388771143079177\n",
            "[[3514 1148  187   50]\n",
            " [ 653 1906   41   36]\n",
            " [ 556  195 1443   31]\n",
            " [ 195   12    5  235]]\n",
            "comment F1-score: 0.7159009880818987\n",
            "unrelated F1-score: 0.6464303883330507\n",
            "support F1-score: 0.7398103050499871\n",
            "refute F1-score: 0.5882352941176471\n",
            "Accu: 0.6954051141373567\n",
            "F1-Weighted 0.6975809297017687\n",
            "F1-Avg 0.6725942438956459\n",
            "[1/5]     train_loss: 7.33716 valid_loss: 12.38877\n",
            "\n",
            "\n",
            "========= Beginning 3 epoch ==========\n",
            "Train loss at 0: 5.241151809692383\n",
            "Train loss at 100: 3.679081439971924\n",
            "Train loss at 200: 10.727958679199219\n",
            "Train loss at 300: 4.290062427520752\n",
            "Train loss at 400: 7.3527960777282715\n",
            "Train loss at 500: 4.810107231140137\n",
            "Train loss at 600: 1.833574652671814\n",
            "Train loss at 700: 12.346245765686035\n",
            "Train loss at 800: 5.977783679962158\n",
            "Train loss at 900: 2.165976047515869\n",
            "Train loss at 1000: 1.507145643234253\n",
            "Train loss at 1100: 6.313686370849609\n",
            "EVALUATING:\n",
            "Valid_loss 12.669125791253714\n",
            "[[3464 1129  235   71]\n",
            " [ 610 1934   55   37]\n",
            " [ 455  211 1533   26]\n",
            " [ 172   18    8  249]]\n",
            "comment F1-score: 0.7216666666666667\n",
            "unrelated F1-score: 0.6524966261808367\n",
            "support F1-score: 0.7559171597633136\n",
            "refute F1-score: 0.6\n",
            "Accu: 0.7034388164984814\n",
            "F1-Weighted 0.7059411959523914\n",
            "F1-Avg 0.6825201131527042\n",
            "[2/5]     train_loss: 6.18974 valid_loss: 12.66913\n",
            "\n",
            "\n",
            "========= Beginning 4 epoch ==========\n",
            "Train loss at 0: 4.987041473388672\n",
            "Train loss at 100: 2.389252185821533\n",
            "Train loss at 200: 7.3196940422058105\n",
            "Train loss at 300: 3.2107813358306885\n",
            "Train loss at 400: 4.392222881317139\n",
            "Train loss at 500: 8.352170944213867\n",
            "Train loss at 600: 1.5337196588516235\n",
            "Train loss at 700: 12.380565643310547\n",
            "Train loss at 800: 5.11959981918335\n",
            "Train loss at 900: 1.2356252670288086\n",
            "Train loss at 1000: 2.0544307231903076\n",
            "Train loss at 1100: 2.7709131240844727\n",
            "EVALUATING:\n",
            "Valid_loss 14.236169745182169\n",
            "[[3274 1302  270   53]\n",
            " [ 542 1988   67   39]\n",
            " [ 378  245 1574   28]\n",
            " [ 168   22    6  251]]\n",
            "comment F1-score: 0.7070510743980132\n",
            "unrelated F1-score: 0.6420151784272566\n",
            "support F1-score: 0.7600193143408981\n",
            "refute F1-score: 0.6136919315403423\n",
            "Accu: 0.6943274223572058\n",
            "F1-Weighted 0.697713186207225\n",
            "F1-Avg 0.6806943746766275\n",
            "[3/5]     train_loss: 5.24775 valid_loss: 14.23617\n",
            "\n",
            "\n",
            "========= Beginning 5 epoch ==========\n",
            "Train loss at 0: 3.1183321475982666\n",
            "Train loss at 100: 1.8600236177444458\n",
            "Train loss at 200: 7.486626148223877\n",
            "Train loss at 300: 3.604979991912842\n",
            "Train loss at 400: 2.7126996517181396\n",
            "Train loss at 500: 4.826478481292725\n",
            "Train loss at 600: 1.1840698719024658\n",
            "Train loss at 700: 11.310340881347656\n",
            "Train loss at 800: 3.9832346439361572\n",
            "Train loss at 900: 1.1191599369049072\n",
            "Train loss at 1000: 1.3295376300811768\n",
            "Train loss at 1100: 2.4048266410827637\n",
            "EVALUATING:\n",
            "Valid_loss 13.76863379893258\n",
            "[[3536 1065  217   81]\n",
            " [ 655 1874   55   52]\n",
            " [ 471  171 1553   30]\n",
            " [ 165   11    6  265]]\n",
            "comment F1-score: 0.7271231749948591\n",
            "unrelated F1-score: 0.651033524405072\n",
            "support F1-score: 0.7657790927021696\n",
            "refute F1-score: 0.6057142857142858\n",
            "Accu: 0.7081414715391398\n",
            "F1-Weighted 0.7105823034788085\n",
            "F1-Avg 0.6874125194540966\n",
            "[4/5]     train_loss: 4.63549 valid_loss: 13.76863\n",
            "/content/gdrive/My Drive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CVS_AET_target\n",
            "Total time taken (mins):  37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ANTM_CI"
      ],
      "metadata": {
        "id": "ONTkE_dipF-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='ANTM_CI' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=2 --lr=1e-5\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPAovL_-tFS2",
        "outputId": "f824052d-6de7-41b2-9ec8-723eddaa589e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = True\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 19429 0 9927\n",
            "Length of train, eval_set: 15540 3889\n",
            "Before shuffling train[0] =  971761970117357568 | After shuffling train[0] =  976194260625252352\n",
            "/content/gdrive/My Drive/NLP Stance Detection/Code_Kaushal/saves/wtwt_ANTM_CI_target\n",
            "1. Type of train dataset\n",
            "Length of train: 15540\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 972  | num_data= 15540\n",
            "97\n",
            "Eval_dataset: num_batches= 244  | num_data= 3889\n",
            "97\n",
            "Dataset created\n",
            "Sun Apr 10 04:54:12 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    59W / 149W |    335MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Model created\n",
            "Sun Apr 10 04:54:15 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P0    60W / 149W |    335MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 22.304283142089844\n",
            "Train loss at 100: 14.465860366821289\n",
            "Train loss at 200: 13.413431167602539\n",
            "Train loss at 300: 13.065494537353516\n",
            "Train loss at 400: 16.349767684936523\n",
            "Train loss at 500: 9.526177406311035\n",
            "Train loss at 600: 16.262428283691406\n",
            "Train loss at 700: 5.820808410644531\n",
            "Train loss at 800: 14.459640502929688\n",
            "Train loss at 900: 11.719948768615723\n",
            "EVALUATING:\n",
            "Valid_loss 13.56952188396063\n",
            "[[970 102  62 451]\n",
            " [343 768  26  54]\n",
            " [ 89  13 348  46]\n",
            " [ 42  11   6 558]]\n",
            "comment F1-score: 0.6404754044239024\n",
            "unrelated F1-score: 0.7366906474820144\n",
            "support F1-score: 0.7420042643923241\n",
            "refute F1-score: 0.6465816917728853\n",
            "Accu: 0.6798662895345847\n",
            "F1-Weighted 0.6838588573220435\n",
            "F1-Avg 0.6914380020177815\n",
            "[0/5]     train_loss: 12.54105 valid_loss: 13.56952\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 9.691740036010742\n",
            "Train loss at 100: 10.369770050048828\n",
            "Train loss at 200: 4.688626289367676\n",
            "Train loss at 300: 12.526899337768555\n",
            "Train loss at 400: 11.055965423583984\n",
            "Train loss at 500: 13.812780380249023\n",
            "Train loss at 600: 16.634540557861328\n",
            "Train loss at 700: 5.068998336791992\n",
            "Train loss at 800: 10.288418769836426\n",
            "Train loss at 900: 8.515953063964844\n",
            "EVALUATING:\n",
            "Valid_loss 12.133755357050505\n",
            "[[1070  200   88  227]\n",
            " [ 211  941   17   22]\n",
            " [ 106   30  342   18]\n",
            " [  76   31   19  491]]\n",
            "comment F1-score: 0.7020997375328084\n",
            "unrelated F1-score: 0.7864605098203091\n",
            "support F1-score: 0.7110187110187111\n",
            "refute F1-score: 0.7141818181818181\n",
            "Accu: 0.7312933916173824\n",
            "F1-Weighted 0.7309894609588459\n",
            "F1-Avg 0.7284401941384118\n",
            "[1/5]     train_loss: 9.70452 valid_loss: 12.13376\n",
            "\n",
            "\n",
            "========= Beginning 3 epoch ==========\n",
            "Train loss at 0: 12.54499626159668\n",
            "Train loss at 100: 8.530450820922852\n",
            "Train loss at 200: 7.123714447021484\n",
            "Train loss at 300: 11.472386360168457\n",
            "Train loss at 400: 11.35003662109375\n",
            "Train loss at 500: 9.904623031616211\n",
            "Train loss at 600: 7.786433696746826\n",
            "Train loss at 700: 3.9065489768981934\n",
            "Train loss at 800: 9.749307632446289\n",
            "Train loss at 900: 13.734139442443848\n",
            "EVALUATING:\n",
            "Valid_loss 12.90920910483501\n",
            "[[948 161 187 289]\n",
            " [182 919  48  42]\n",
            " [ 53  16 403  24]\n",
            " [ 51  18  32 516]]\n",
            "comment F1-score: 0.6725789286981199\n",
            "unrelated F1-score: 0.7973969631236442\n",
            "support F1-score: 0.6912521440823328\n",
            "refute F1-score: 0.6935483870967741\n",
            "Accu: 0.716379532013371\n",
            "F1-Weighted 0.7165126776472941\n",
            "F1-Avg 0.7136941057502177\n",
            "[2/5]     train_loss: 7.71892 valid_loss: 12.90921\n",
            "\n",
            "\n",
            "========= Beginning 4 epoch ==========\n",
            "Train loss at 0: 7.328449726104736\n",
            "Train loss at 100: 6.692278861999512\n",
            "Train loss at 200: 6.347149848937988\n",
            "Train loss at 300: 9.85848617553711\n",
            "Train loss at 400: 8.431262969970703\n",
            "Train loss at 500: 10.220720291137695\n",
            "Train loss at 600: 10.664999008178711\n",
            "Train loss at 700: 3.126966714859009\n",
            "Train loss at 800: 12.09597110748291\n",
            "Train loss at 900: 14.055770874023438\n",
            "EVALUATING:\n",
            "Valid_loss 13.17617638286997\n",
            "[[1074  153  151  207]\n",
            " [ 209  894   62   26]\n",
            " [  69   13  395   19]\n",
            " [  90   24   48  455]]\n",
            "comment F1-score: 0.709613478691774\n",
            "unrelated F1-score: 0.785934065934066\n",
            "support F1-score: 0.685763888888889\n",
            "refute F1-score: 0.6873111782477341\n",
            "Accu: 0.7246078683466187\n",
            "F1-Weighted 0.7264064597895795\n",
            "F1-Avg 0.7171556529406158\n",
            "[3/5]     train_loss: 6.97168 valid_loss: 13.17618\n",
            "\n",
            "\n",
            "========= Beginning 5 epoch ==========\n",
            "Train loss at 0: 5.9970269203186035\n",
            "Train loss at 100: 8.487934112548828\n",
            "Train loss at 200: 21.226593017578125\n",
            "Train loss at 300: 21.308801651000977\n",
            "Train loss at 400: 19.779083251953125\n",
            "Train loss at 500: 19.726530075073242\n",
            "Train loss at 600: 20.672645568847656\n",
            "Train loss at 700: 18.22630500793457\n",
            "Train loss at 800: 20.784196853637695\n",
            "Train loss at 900: 21.712020874023438\n",
            "EVALUATING:\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Valid_loss 22.1631711960816\n",
            "[[1585    0    0    0]\n",
            " [1191    0    0    0]\n",
            " [ 496    0    0    0]\n",
            " [ 617    0    0    0]]\n",
            "comment F1-score: 0.5791012056996712\n",
            "unrelated F1-score: 0.0\n",
            "support F1-score: 0.0\n",
            "refute F1-score: 0.0\n",
            "Accu: 0.40755978400617127\n",
            "F1-Weighted 0.23601836231267134\n",
            "F1-Avg 0.1447753014249178\n",
            "[4/5]     train_loss: 17.56478 valid_loss: 22.16317\n",
            "Total time taken (mins):  33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AET_HUM"
      ],
      "metadata": {
        "id": "YCvArUEapJ8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# target\n",
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='AET_HUM' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=2 --lr=1e-5\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99YZ8Wln8R9a",
        "outputId": "e8dd1ed2-9a32-45ba-953a-aa3e0f3d2e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = True\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 22360 0 6996\n",
            "Length of train, eval_set: 22360 6996\n",
            "Before shuffling train[0] =  971761970117357568 | After shuffling train[0] =  861275445450244097\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_AET_HUM_target\n",
            "1. Type of train dataset\n",
            "Length of train: 22360\n",
            "Downloading: 100% 558/558 [00:00<00:00, 561kB/s]\n",
            "Downloading: 100% 843k/843k [00:00<00:00, 2.04MB/s]\n",
            "Downloading: 100% 1.08M/1.08M [00:00<00:00, 2.20MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1398  | num_data= 22360\n",
            "97\n",
            "Eval_dataset: num_batches= 438  | num_data= 6996\n",
            "97\n",
            "Dataset created\n",
            "Mon Apr 11 00:13:34 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    57W / 149W |    347MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Downloading: 100% 543M/543M [00:15<00:00, 35.8MB/s]\n",
            "Model created\n",
            "Mon Apr 11 00:13:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    57W / 149W |    347MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 21.99962043762207\n",
            "Train loss at 100: 16.786788940429688\n",
            "Train loss at 200: 13.03991985321045\n",
            "Train loss at 300: 6.862030506134033\n",
            "Train loss at 400: 8.999654769897461\n",
            "Train loss at 500: 11.596370697021484\n",
            "Train loss at 600: 6.639548301696777\n",
            "Train loss at 700: 7.751112937927246\n",
            "Train loss at 800: 12.330621719360352\n",
            "Train loss at 900: 9.406332015991211\n",
            "Train loss at 1000: 9.110044479370117\n",
            "Train loss at 1100: 4.168920993804932\n",
            "Train loss at 1200: 13.6277437210083\n",
            "Train loss at 1300: 5.653741836547852\n",
            "EVALUATING:\n",
            "Valid_loss 9.867584053512033\n",
            "[[1957  387  116   78]\n",
            " [ 291 2169   48   15]\n",
            " [ 193   72  645   27]\n",
            " [ 294   48   23  633]]\n",
            "comment F1-score: 0.742271951450787\n",
            "unrelated F1-score: 0.8343912290825158\n",
            "support F1-score: 0.7292255511588468\n",
            "refute F1-score: 0.7230154197601371\n",
            "Accu: 0.7724413950829045\n",
            "F1-Weighted 0.7709990014456463\n",
            "F1-Avg 0.7572260378630717\n",
            "[0/2]     train_loss: 10.55818 valid_loss: 9.86758\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 10.187602043151855\n",
            "Train loss at 100: 8.130061149597168\n",
            "Train loss at 200: 4.136658668518066\n",
            "Train loss at 300: 5.208573818206787\n",
            "Train loss at 400: 6.710473537445068\n",
            "Train loss at 500: 13.677225112915039\n",
            "Train loss at 600: 5.927854537963867\n",
            "Train loss at 700: 4.632608413696289\n",
            "Train loss at 800: 12.819700241088867\n",
            "Train loss at 900: 8.87980842590332\n",
            "Train loss at 1000: 6.17559814453125\n",
            "Train loss at 1100: 3.49312424659729\n",
            "Train loss at 1200: 12.427629470825195\n",
            "Train loss at 1300: 2.910985231399536\n",
            "EVALUATING:\n",
            "Valid_loss 9.559376674155667\n",
            "[[2050  274  120   94]\n",
            " [ 330 2116   62   15]\n",
            " [ 192   45  666   34]\n",
            " [ 276   36   19  667]]\n",
            "comment F1-score: 0.7612328258447828\n",
            "unrelated F1-score: 0.8474169002803364\n",
            "support F1-score: 0.738359201773836\n",
            "refute F1-score: 0.7378318584070795\n",
            "Accu: 0.7860205831903945\n",
            "F1-Weighted 0.7859120237498138\n",
            "F1-Avg 0.7712101965765087\n",
            "[1/2]     train_loss: 7.23091 valid_loss: 9.55938\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_AET_HUM_target\n",
            "Total time taken (mins):  19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# notarget\n",
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='AET_HUM' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=2 --lr=1e-5 --notarget\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn6YysTbG1XU",
        "outputId": "b39bb607-336f-4ea5-c9ad-eb5bf27be22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = False\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 22360 0 6996\n",
            "Length of train, eval_set: 22360 6996\n",
            "Before shuffling train[0] =  971761970117357568 | After shuffling train[0] =  861275445450244097\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_AET_HUM_notarget\n",
            "1. Type of train dataset\n",
            "Length of train: 22360\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1398  | num_data= 22360\n",
            "91\n",
            "Eval_dataset: num_batches= 438  | num_data= 6996\n",
            "91\n",
            "Dataset created\n",
            "Mon Apr 11 00:53:16 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    58W / 149W |    343MiB / 11441MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Model created\n",
            "Mon Apr 11 00:53:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    58W / 149W |    343MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 22.05508804321289\n",
            "Train loss at 100: 16.402254104614258\n",
            "Train loss at 200: 11.424614906311035\n",
            "Train loss at 300: 8.050885200500488\n",
            "Train loss at 400: 8.41867733001709\n",
            "Train loss at 500: 11.696306228637695\n",
            "Train loss at 600: 8.612150192260742\n",
            "Train loss at 700: 6.233981132507324\n",
            "Train loss at 800: 11.865645408630371\n",
            "Train loss at 900: 9.586726188659668\n",
            "Train loss at 1000: 7.850341796875\n",
            "Train loss at 1100: 3.3017594814300537\n",
            "Train loss at 1200: 14.581140518188477\n",
            "Train loss at 1300: 6.142574787139893\n",
            "EVALUATING:\n",
            "Valid_loss 10.238863862540624\n",
            "[[1898  400  169   71]\n",
            " [ 279 2171   61   12]\n",
            " [ 166   89  659   23]\n",
            " [ 305   55   35  603]]\n",
            "comment F1-score: 0.7319706903200925\n",
            "unrelated F1-score: 0.8289423444062619\n",
            "support F1-score: 0.708221386351424\n",
            "refute F1-score: 0.7065026362038664\n",
            "Accu: 0.7620068610634648\n",
            "F1-Weighted 0.7601281041898423\n",
            "F1-Avg 0.7439092643204112\n",
            "[0/2]     train_loss: 10.45448 valid_loss: 10.23886\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 10.57999038696289\n",
            "Train loss at 100: 9.589251518249512\n",
            "Train loss at 200: 3.695700168609619\n",
            "Train loss at 300: 4.036079406738281\n",
            "Train loss at 400: 6.618494033813477\n",
            "Train loss at 500: 12.464380264282227\n",
            "Train loss at 600: 5.544520378112793\n",
            "Train loss at 700: 5.6357855796813965\n",
            "Train loss at 800: 12.727762222290039\n",
            "Train loss at 900: 10.79049015045166\n",
            "Train loss at 1000: 5.349467754364014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ci-ESRX"
      ],
      "metadata": {
        "id": "SNe79jOJ8S5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='CI_ESRX' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=2 --lr=1e-5\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coJJ1POg9faC",
        "outputId": "acd808a2-c7ab-40df-c8c7-6b302342c816"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = True\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 27130 0 2226\n",
            "Length of train, eval_set: 27130 2226\n",
            "Before shuffling train[0] =  944165633889095681 | After shuffling train[0] =  831878268378816513\n",
            "/content/gdrive/My Drive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CI_ESRX_target\n",
            "1. Type of train dataset\n",
            "Length of train: 27130\n",
            "Downloading: 100% 558/558 [00:00<00:00, 510kB/s]\n",
            "Downloading: 100% 843k/843k [00:00<00:00, 2.09MB/s]\n",
            "Downloading: 100% 1.08M/1.08M [00:00<00:00, 2.18MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1696  | num_data= 27130\n",
            "97\n",
            "Eval_dataset: num_batches= 140  | num_data= 2226\n",
            "97\n",
            "Dataset created\n",
            "Mon Apr 11 03:06:45 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    56W / 149W |    347MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Downloading: 100% 543M/543M [00:14<00:00, 37.4MB/s]\n",
            "Model created\n",
            "Mon Apr 11 03:07:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    57W / 149W |    347MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 22.219301223754883\n",
            "Train loss at 100: 18.632858276367188\n",
            "Train loss at 200: 13.247836112976074\n",
            "Train loss at 300: 11.746932029724121\n",
            "Train loss at 400: 11.611658096313477\n",
            "Train loss at 500: 13.503796577453613\n",
            "Train loss at 600: 5.513715744018555\n",
            "Train loss at 700: 7.588998794555664\n",
            "Train loss at 800: 7.512302398681641\n",
            "Train loss at 900: 7.320611953735352\n",
            "Train loss at 1000: 13.889825820922852\n",
            "Train loss at 1100: 5.996020793914795\n",
            "Train loss at 1200: 6.951878547668457\n",
            "Train loss at 1300: 7.180118083953857\n",
            "Train loss at 1400: 9.210040092468262\n",
            "Train loss at 1500: 10.089544296264648\n",
            "Train loss at 1600: 10.990484237670898\n",
            "EVALUATING:\n",
            "Valid_loss 16.560371903010775\n",
            "[[497 242  72  41]\n",
            " [ 46 354  29  32]\n",
            " [ 43 198 399  48]\n",
            " [ 49  25  10 141]]\n",
            "comment F1-score: 0.6684599865501009\n",
            "unrelated F1-score: 0.5531250000000001\n",
            "support F1-score: 0.6661101836393991\n",
            "refute F1-score: 0.5790554414784395\n",
            "Accu: 0.6248876909254267\n",
            "F1-Weighted 0.6348112372943582\n",
            "F1-Avg 0.6166876529169849\n",
            "[0/2]     train_loss: 10.33340 valid_loss: 16.56037\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 9.291361808776855\n",
            "Train loss at 100: 7.972591400146484\n",
            "Train loss at 200: 9.42314338684082\n",
            "Train loss at 300: 6.524302005767822\n",
            "Train loss at 400: 8.287065505981445\n",
            "Train loss at 500: 8.735639572143555\n",
            "Train loss at 600: 2.3248584270477295\n",
            "Train loss at 700: 8.418896675109863\n",
            "Train loss at 800: 4.7519683837890625\n",
            "Train loss at 900: 8.205547332763672\n",
            "Train loss at 1000: 9.914307594299316\n",
            "Train loss at 1100: 3.839865207672119\n",
            "Train loss at 1200: 5.055063724517822\n",
            "Train loss at 1300: 5.500517845153809\n",
            "Train loss at 1400: 8.629655838012695\n",
            "Train loss at 1500: 8.726070404052734\n",
            "Train loss at 1600: 10.679974555969238\n",
            "EVALUATING:\n",
            "Valid_loss 15.48462039402553\n",
            "[[526 198  89  39]\n",
            " [ 41 358  33  29]\n",
            " [ 40 159 453  36]\n",
            " [ 46  29  10 140]]\n",
            "comment F1-score: 0.6990033222591363\n",
            "unrelated F1-score: 0.5941908713692946\n",
            "support F1-score: 0.7117046347211313\n",
            "refute F1-score: 0.5970149253731343\n",
            "Accu: 0.6635220125786163\n",
            "F1-Weighted 0.6709137327776831\n",
            "F1-Avg 0.6504784384306741\n",
            "[1/2]     train_loss: 7.26806 valid_loss: 15.48462\n",
            "/content/gdrive/My Drive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CI_ESRX_target\n",
            "Total time taken (mins):  21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='CI_ESRX' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=5 --lr=3e-6 --notarget\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))"
      ],
      "metadata": {
        "id": "SRxL7JWgHuWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff20300-3f09-40a4-fc6a-9612efdbed47"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = False\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 27130 0 2226\n",
            "Length of train, eval_set: 27130 2226\n",
            "Before shuffling train[0] =  944165633889095681 | After shuffling train[0] =  831878268378816513\n",
            "/content/gdrive/My Drive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CI_ESRX_notarget\n",
            "1. Type of train dataset\n",
            "Length of train: 27130\n",
            "Downloading: 100% 558/558 [00:00<00:00, 534kB/s]\n",
            "Downloading: 100% 843k/843k [00:00<00:00, 4.80MB/s]\n",
            "Downloading: 100% 1.08M/1.08M [00:00<00:00, 5.89MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1696  | num_data= 27130\n",
            "91\n",
            "Eval_dataset: num_batches= 140  | num_data= 2226\n",
            "91\n",
            "Dataset created\n",
            "Mon Apr 11 04:25:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    60W / 149W |    343MiB / 11441MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Downloading: 100% 543M/543M [00:12<00:00, 43.3MB/s]\n",
            "Model created\n",
            "Mon Apr 11 04:26:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    60W / 149W |    343MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 21.98110008239746\n",
            "Train loss at 100: 20.87847137451172\n",
            "Train loss at 200: 18.760215759277344\n",
            "Train loss at 300: 15.54784870147705\n",
            "Train loss at 400: 15.071621894836426\n",
            "Train loss at 500: 15.77697467803955\n",
            "Train loss at 600: 9.486862182617188\n",
            "Train loss at 700: 12.452715873718262\n",
            "Train loss at 800: 12.063050270080566\n",
            "Train loss at 900: 9.907565116882324\n",
            "Train loss at 1000: 10.855551719665527\n",
            "Train loss at 1100: 7.244797706604004\n",
            "Train loss at 1200: 8.060665130615234\n",
            "Train loss at 1300: 8.982154846191406\n",
            "Train loss at 1400: 11.672779083251953\n",
            "Train loss at 1500: 9.52711009979248\n",
            "Train loss at 1600: 9.882978439331055\n",
            "EVALUATING:\n",
            "Valid_loss 14.572220918110439\n",
            "[[537 177  99  39]\n",
            " [ 64 334  30  33]\n",
            " [ 72 116 452  48]\n",
            " [ 75  15  12 123]]\n",
            "comment F1-score: 0.67125\n",
            "unrelated F1-score: 0.6056210335448776\n",
            "support F1-score: 0.7056986729117877\n",
            "refute F1-score: 0.5256410256410257\n",
            "Accu: 0.6495956873315364\n",
            "F1-Weighted 0.6535876973031127\n",
            "F1-Avg 0.6270526830244227\n",
            "[0/5]     train_loss: 12.86143 valid_loss: 14.57222\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 8.071639060974121\n",
            "Train loss at 100: 6.815237045288086\n",
            "Train loss at 200: 11.45974349975586\n",
            "Train loss at 300: 8.108297348022461\n",
            "Train loss at 400: 8.776220321655273\n",
            "Train loss at 500: 10.11447811126709\n",
            "Train loss at 600: 4.1185784339904785\n",
            "Train loss at 700: 8.368123054504395\n",
            "Train loss at 800: 8.28407096862793\n",
            "Train loss at 900: 8.930373191833496\n",
            "Train loss at 1000: 8.568662643432617\n",
            "Train loss at 1100: 4.701773166656494\n",
            "Train loss at 1200: 6.625244617462158\n",
            "Train loss at 1300: 9.873583793640137\n",
            "Train loss at 1400: 9.852100372314453\n",
            "Train loss at 1500: 8.346353530883789\n",
            "Train loss at 1600: 10.662800788879395\n",
            "EVALUATING:\n",
            "Valid_loss 14.231492454665048\n",
            "[[553 153 111  35]\n",
            " [ 69 321  39  32]\n",
            " [ 57 101 487  43]\n",
            " [ 67  15  15 128]]\n",
            "comment F1-score: 0.6921151439299125\n",
            "unrelated F1-score: 0.610846812559467\n",
            "support F1-score: 0.7268656716417911\n",
            "refute F1-score: 0.5529157667386609\n",
            "Accu: 0.6689128481581311\n",
            "F1-Weighted 0.6719551270547847\n",
            "F1-Avg 0.6456858487174579\n",
            "[1/5]     train_loss: 8.49645 valid_loss: 14.23149\n",
            "\n",
            "\n",
            "========= Beginning 3 epoch ==========\n",
            "Train loss at 0: 8.238080978393555\n",
            "Train loss at 100: 6.287590503692627\n",
            "Train loss at 200: 10.440542221069336\n",
            "Train loss at 300: 7.159487724304199\n",
            "Train loss at 400: 7.939234256744385\n",
            "Train loss at 500: 9.76717758178711\n",
            "Train loss at 600: 3.7266321182250977\n",
            "Train loss at 700: 8.280806541442871\n",
            "Train loss at 800: 6.938385009765625\n",
            "Train loss at 900: 10.608099937438965\n",
            "Train loss at 1000: 7.334036827087402\n",
            "Train loss at 1100: 4.018189430236816\n",
            "Train loss at 1200: 6.172428131103516\n",
            "Train loss at 1300: 6.445855140686035\n",
            "Train loss at 1400: 7.191295146942139\n",
            "Train loss at 1500: 8.258008003234863\n",
            "Train loss at 1600: 9.142441749572754\n",
            "EVALUATING:\n",
            "Valid_loss 14.119671520165035\n",
            "[[606 124  85  37]\n",
            " [ 71 324  34  32]\n",
            " [ 80  99 472  37]\n",
            " [ 66  13  11 135]]\n",
            "comment F1-score: 0.7235820895522389\n",
            "unrelated F1-score: 0.6346718903036238\n",
            "support F1-score: 0.7317829457364341\n",
            "refute F1-score: 0.5793991416309013\n",
            "Accu: 0.6904761904761905\n",
            "F1-Weighted 0.6931298990395767\n",
            "F1-Avg 0.6673590168057995\n",
            "[2/5]     train_loss: 7.51760 valid_loss: 14.11967\n",
            "\n",
            "\n",
            "========= Beginning 4 epoch ==========\n",
            "Train loss at 0: 9.660932540893555\n",
            "Train loss at 100: 7.657724380493164\n",
            "Train loss at 200: 9.18681812286377\n",
            "Train loss at 300: 5.7896623611450195\n",
            "Train loss at 400: 8.456886291503906\n",
            "Train loss at 500: 7.759136199951172\n",
            "Train loss at 600: 2.567965507507324\n",
            "Train loss at 700: 8.739317893981934\n",
            "Train loss at 800: 7.30572509765625\n",
            "Train loss at 900: 8.974081039428711\n",
            "Train loss at 1000: 6.876834392547607\n",
            "Train loss at 1100: 4.313320159912109\n",
            "Train loss at 1200: 7.172011375427246\n",
            "Train loss at 1300: 7.096677303314209\n",
            "Train loss at 1400: 5.920767307281494\n",
            "Train loss at 1500: 7.34610652923584\n",
            "Train loss at 1600: 8.278770446777344\n",
            "EVALUATING:\n",
            "Valid_loss 13.935185490335737\n",
            "[[600 126  93  33]\n",
            " [ 66 321  44  30]\n",
            " [ 67  79 508  34]\n",
            " [ 59  16  14 136]]\n",
            "comment F1-score: 0.7299270072992701\n",
            "unrelated F1-score: 0.6400797607178464\n",
            "support F1-score: 0.7542687453600594\n",
            "refute F1-score: 0.593886462882096\n",
            "Accu: 0.7030548068283917\n",
            "F1-Weighted 0.70509251161999\n",
            "F1-Avg 0.6795404940648181\n",
            "[3/5]     train_loss: 6.83123 valid_loss: 13.93519\n",
            "\n",
            "\n",
            "========= Beginning 5 epoch ==========\n",
            "Train loss at 0: 7.782689094543457\n",
            "Train loss at 100: 6.157403469085693\n",
            "Train loss at 200: 7.974656581878662\n",
            "Train loss at 300: 5.432286262512207\n",
            "Train loss at 400: 5.32805061340332\n",
            "Train loss at 500: 9.603320121765137\n",
            "Train loss at 600: 3.3659253120422363\n",
            "Train loss at 700: 6.535801887512207\n",
            "Train loss at 800: 7.56016731262207\n",
            "Train loss at 900: 7.995748043060303\n",
            "Train loss at 1000: 7.765700340270996\n",
            "Train loss at 1100: 2.7674126625061035\n",
            "Train loss at 1200: 4.686110496520996\n",
            "Train loss at 1300: 6.445418357849121\n",
            "Train loss at 1400: 5.643466949462891\n",
            "Train loss at 1500: 5.746974945068359\n",
            "Train loss at 1600: 9.084978103637695\n",
            "EVALUATING:\n",
            "Valid_loss 15.23717598404203\n",
            "[[583 152  83  34]\n",
            " [ 64 331  36  30]\n",
            " [ 59 117 478  34]\n",
            " [ 60  22  13 130]]\n",
            "comment F1-score: 0.7206427688504328\n",
            "unrelated F1-score: 0.6112650046168051\n",
            "support F1-score: 0.736517719568567\n",
            "refute F1-score: 0.5739514348785872\n",
            "Accu: 0.683737646001797\n",
            "F1-Weighted 0.6880701123538959\n",
            "F1-Avg 0.660594231978598\n",
            "[4/5]     train_loss: 6.31182 valid_loss: 15.23718\n",
            "/content/gdrive/My Drive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CI_ESRX_notarget\n",
            "Total time taken (mins):  47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "p7INopmBPwIp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}