{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tWT_WT Results.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8pc1KOFHwbgcxsMfRPvHZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mangalm96/explainablenlp-info259/blob/main/tWT_WT_Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1Fg2cSL7mbe",
        "outputId": "4806acdf-d8b4-4992-cc8a-e049ee299690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "data = open(\"/content/gdrive/MyDrive/NLP Project/stance-dataset/dataset/data_new.json\")\n",
        "data_list = json.load(data)"
      ],
      "metadata": {
        "id": "z9cUlJwR7sfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stance_dict = dict()\n",
        "for record in data_list:\n",
        "  stance = record[\"stance\"]\n",
        "  stance_dict[stance] = stance_dict.get(stance, 0) + 1"
      ],
      "metadata": {
        "id": "C30Y3nss74Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stance_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a94PtCN766M",
        "outputId": "4d95c395-1271-47a0-d9f4-25ac4bcbc2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'comment': 26952, 'refute': 9742, 'support': 9742, 'unrelated': 49298}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# original dataset\n",
        "data = open(\"/content/gdrive/MyDrive/NLP Stance Detection/Code_Kaushal/data/wtwt/data.json\")\n",
        "data_list_biased = json.load(data)\n",
        "\n",
        "stance_dict_bias = dict()\n",
        "for record in data_list_biased:\n",
        "  stance = record[\"stance\"]\n",
        "  stance_dict_bias[stance] = stance_dict_bias.get(stance, 0) + 1\n",
        "\n",
        "\n",
        "stance_dict_bias "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7HfckWZ78Kx",
        "outputId": "0664c9e4-f9ef-4531-b78a-7996cecf3b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'comment': 18087, 'refute': 3791, 'support': 5951, 'unrelated': 16169}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_list_biased[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DN1dbl48hho",
        "outputId": "f5a8d817-0a41-4fbd-9e64-f0cecb2b6560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'merger': 'CI_ESRX',\n",
              " 'stance': 'support',\n",
              " 'target': 'Cigna Express_Scripts',\n",
              " 'text': ['Cigna',\n",
              "  'and',\n",
              "  'ESI',\n",
              "  'set',\n",
              "  'to',\n",
              "  'merge',\n",
              "  '.',\n",
              "  'Here',\n",
              "  'we',\n",
              "  'go',\n",
              "  '.'],\n",
              " 'tweet_id': '971761970117357568'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in data_list:\n",
        "  if k['merger'] == \"CI_ESRX\" and k['tweet_id'] == '971761970117357568' :\n",
        "    print(k)\n",
        "    print(k['stance'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwtfHLMA8k7d",
        "outputId": "1ebebda9-7072-4cc5-bd92-60c6c29eed6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tweet_id': '971761970117357568', 'merger': 'CI_ESRX', 'stance': 'support', 'target': ['Cigna', 'Express_Scripts'], 'text': ['Cigna', 'and', 'ESI', 'set', 'to', 'merge', '.', 'Here', 'we', 'go', '.']}\n",
            "support\n",
            "{'tweet_id': '971761970117357568', 'merger': 'CI_ESRX', 'stance': 'refute', 'target': ['Cigna', 'Express_Scripts'], 'text': ['Cigna', 'and', 'ESI', 'set', 'to', 'merge', '.', 'Here', 'we', 'go', '.']}\n",
            "refute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in data_list:\n",
        "  if k['tweet_id'] == '971761970117357568' :\n",
        "    print(k)\n",
        "    print(k['stance'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94_f1h6TLxoO",
        "outputId": "6614d8b7-c2bb-4db5-e368-4d3ddfd9129d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tweet_id': '971761970117357568', 'merger': 'CI_ESRX', 'stance': 'support', 'target': ['Cigna', 'Express_Scripts'], 'text': ['Cigna', 'and', 'ESI', 'set', 'to', 'merge', '.', 'Here', 'we', 'go', '.']}\n",
            "support\n",
            "{'tweet_id': '971761970117357568', 'merger': 'CI_ESRX', 'stance': 'refute', 'target': ['Cigna', 'Express_Scripts'], 'text': ['Cigna', 'and', 'ESI', 'set', 'to', 'merge', '.', 'Here', 'we', 'go', '.']}\n",
            "refute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in data_list_biased:\n",
        "  if k['merger'] == \"CI_ESRX\" and k['tweet_id'] == '971761970117357568' :\n",
        "    print(k)\n",
        "    print(k['stance'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNQWQxox8Vs-",
        "outputId": "4b26fea2-cf5d-4b9b-df06-2c533e8ec3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "support\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# original dataset\n",
        "data = open(\"/content/gdrive/MyDrive/NLP Stance Detection/Code_Kaushal/data/twt_wt/wtwt_new.json\")\n",
        "data_list_twtwt = json.load(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "3d_qHmBV8aGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in data_list_twtwt:\n",
        "  if k['tweet_id'] == '971761970117357568' :\n",
        "    print(k)\n",
        "    print(k['stance'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s87fMAigI97L",
        "outputId": "ad3b8ae1-8b57-42d3-981c-62e30b25af55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tweet_id': '971761970117357568', 'merger': 'CI_ESRX', 'stance': 'support'}\n",
            "support\n",
            "{'tweet_id': '971761970117357568', 'merger': 'NEG_CI_ESRX', 'stance': 'refute'}\n",
            "refute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## run training"
      ],
      "metadata": {
        "id": "rq4EmdvQJI9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==3.5.0\n",
        "!pip install wandb==0.9.4\n",
        "!pip install scikit-learn==0.23.1\n",
        "!pip install scipy==1.5.0\n",
        "!pip install ekphrasis==0.5.1\n",
        "!pip install emoji\n",
        "!pip install captum==0.2.0\n",
        "!pip install python-papi==5.5.1.2\n",
        "!pip install lime==0.2.0.0\n",
        "!pip install torch==1.4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sCLHwocqDiRO",
        "outputId": "b5c70494-870d-412d-8de2-5d212374e8ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.5.0\n",
            "  Downloading transformers-3.5.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 851 kB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2019.12.20)\n",
            "Collecting tokenizers==0.9.3\n",
            "  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (4.64.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.17.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.0) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=59662a930e4b5bce6c27ba5cb0b1ef90706af302e9b0546ccb88e078a28f4b00\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.0\n",
            "Collecting wandb==0.9.4\n",
            "  Downloading wandb-0.9.4-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 97 kB/s \n",
            "\u001b[?25hCollecting watchdog>=0.8.3\n",
            "  Downloading watchdog-2.1.7-py3-none-manylinux2014_x86_64.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 144 kB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 80 kB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (2.8.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "  Downloading sentry_sdk-1.5.11-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 112 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (1.15.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (3.13)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (2.23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 37 kB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (5.4.8)\n",
            "Collecting gql==0.2.0\n",
            "  Downloading gql-0.2.0.tar.gz (18 kB)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (7.352.0)\n",
            "Collecting graphql-core<2,>=0.5.0\n",
            "  Downloading graphql-core-1.1.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 142 kB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from gql==0.2.0->wandb==0.9.4) (2.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb==0.9.4) (4.2.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (1.24.3)\n",
            "Building wheels for collected packages: gql, graphql-core, subprocess32\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-py3-none-any.whl size=7638 sha256=679b5781b60d05c2dc325c0f99f2ec3babf8b90ffc9e299c808d0e77b8cc65ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/9a/56/5456fd32264a8fc53eefcb2f74e24e99a7ef4eb40a9af5c905\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-py3-none-any.whl size=104649 sha256=c3f3e439d359bf36105d0d8a88b5ec5057b37abf43388711ea37bb54d94bd950\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/fd/8c/a20dd591c1a554070cc33fb58042867e6ac1c85395abe2e57a\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=eb12d015ae3d182f62f640a65ccfa4c6ea90348291262b05e7b52e34a0e81f12\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "Successfully built gql graphql-core subprocess32\n",
            "Installing collected packages: smmap, graphql-core, gitdb, watchdog, subprocess32, shortuuid, sentry-sdk, gql, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.27 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 gql-0.2.0 graphql-core-1.1 sentry-sdk-1.5.11 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.9.4 watchdog-2.1.7\n",
            "Collecting scikit-learn==0.23.1\n",
            "  Downloading scikit_learn-0.23.1-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 600 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (3.1.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.1 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.1\n",
            "Collecting scipy==1.5.0\n",
            "  Downloading scipy-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 63.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.5.0) (1.21.6)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.5.0\n",
            "Collecting ekphrasis==0.5.1\n",
            "  Downloading ekphrasis-0.5.1.tar.gz (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (4.64.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting ujson\n",
            "  Downloading ujson-5.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (3.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (3.2.5)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 383 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (1.21.6)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis==0.5.1) (0.2.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->ekphrasis==0.5.1) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->ekphrasis==0.5.1) (1.15.0)\n",
            "Building wheels for collected packages: ekphrasis\n",
            "  Building wheel for ekphrasis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ekphrasis: filename=ekphrasis-0.5.1-py3-none-any.whl size=82842 sha256=83e21c60168e1aa9ee2b3413cdad7bedd6a763d70ffb253a6465d2e3900e822c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/ec/0d/12659e32faf780546945d0120f2c8410eb3efb7426731da88f\n",
            "Successfully built ekphrasis\n",
            "Installing collected packages: ujson, ftfy, colorama, ekphrasis\n",
            "Successfully installed colorama-0.4.4 ekphrasis-0.5.1 ftfy-6.1.1 ujson-5.2.0\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 123 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=2a1940cd631ceee9f9b307f40c77c617f3f1054898c2a449896b216bd244066d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n",
            "Collecting captum==0.2.0\n",
            "  Downloading captum-0.2.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 160 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from captum==0.2.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum==0.2.0) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum==0.2.0) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->captum==0.2.0) (4.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum==0.2.0) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum==0.2.0) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum==0.2.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum==0.2.0) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->captum==0.2.0) (1.15.0)\n",
            "Installing collected packages: captum\n",
            "Successfully installed captum-0.2.0\n",
            "Collecting python-papi==5.5.1.2\n",
            "  Downloading python_papi-5.5.1.2.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 146 kB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from python-papi==5.5.1.2) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->python-papi==5.5.1.2) (2.21)\n",
            "Building wheels for collected packages: python-papi\n",
            "  Building wheel for python-papi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-papi: filename=python_papi-5.5.1.2-cp37-cp37m-linux_x86_64.whl size=861937 sha256=4d6de66471715f76d4b99d85ac0fa6d711b31c9d6698556a2ea52774aa714654\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/16/ab/da4dc99a38cd930d78dd4c5e07db6c618a192c38faf1a37cfd\n",
            "Successfully built python-papi\n",
            "Installing collected packages: python-papi\n",
            "Successfully installed python-papi-5.5.1.2\n",
            "Collecting lime==0.2.0.0\n",
            "  Downloading lime-0.2.0.0.tar.gz (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 62 kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.0) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.0) (1.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.0) (4.64.0)\n",
            "Collecting pillow==5.4.1\n",
            "  Downloading Pillow-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 165 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.0) (0.23.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.0) (0.18.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.0) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.0) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.0) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.0) (2.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.2.0.0) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.2.0.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.2.0.0) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.2.0.0) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->lime==0.2.0.0) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime==0.2.0.0) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime==0.2.0.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime==0.2.0.0) (3.1.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.0-py3-none-any.whl size=284191 sha256=73640ebbd696dd7eac10fcfb560107164667af6c3a983305232917e005805852\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/1a/3f/6b78b5cf3a5b8ed95a487c2539755c9e97907e53594dfe8e35\n",
            "Successfully built lime\n",
            "Installing collected packages: pillow, lime\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 5.4.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed lime-0.2.0.0 pillow-5.4.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |███████████████████████████████▍| 739.7 MB 90 kB/s eta 0:02:32\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 519, in read\n",
            "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 62, in read\n",
            "    data = self.__fp.read(amt)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 465, in read\n",
            "    n = self.readinto(b)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 509, in readinto\n",
            "    n = self.fp.readinto(b)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 589, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 1071, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "  File \"/usr/lib/python3.7/ssl.py\", line 929, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 319, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 128, in resolve\n",
            "    requirements, max_rounds=try_to_avoid_resolution_too_deep\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 473, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 341, in resolve\n",
            "    name, crit = self._merge_into_criterion(r, parent=None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _merge_into_criterion\n",
            "    if not criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/structs.py\", line 139, in __bool__\n",
            "    return bool(self._sequence)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in __bool__\n",
            "    return any(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 129, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 33, in _iter_built\n",
            "    candidate = func()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 205, in _make_candidate_from_link\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 312, in __init__\n",
            "    version=version,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 151, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 234, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 318, in _prepare_distribution\n",
            "    self._ireq, parallel_builds=True\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 508, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 552, in _prepare_linked_requirement\n",
            "    self.download_dir, hashes\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 243, in unpack_url\n",
            "    hashes=hashes,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/prepare.py\", line 102, in get_http_url\n",
            "    from_path, content_type = download(link, temp_dir.path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/network/download.py\", line 157, in __call__\n",
            "    for chunk in chunks:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/progress_bars.py\", line 152, in iter\n",
            "    for x in it:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/network/utils.py\", line 86, in response_chunks\n",
            "    decode_content=False,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 576, in stream\n",
            "    data = self.read(amt=amt, decode_content=decode_content)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 541, in read\n",
            "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/urllib3/response.py\", line 455, in _error_catcher\n",
            "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
            "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: ConnectionResetError(104, 'Connection reset by peer')\", ConnectionResetError(104, 'Connection reset by peer'))\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.4.0"
      ],
      "metadata": {
        "id": "mJL2mkJyLUgP",
        "outputId": "ecb356bc-731b-4314-efc6-4ee06392155c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 7.2 kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "start_time = time.time()\n",
        "\n",
        "!python /content/gdrive/MyDrive/NLP\\ Stance\\ Detection/tWT_WT/train.py \\\n",
        "--dataset_path=\"dataset/data_new.json\" \\\n",
        "--seed=4214 \\\n",
        "--cross_valid_num=4 \\\n",
        "--target_merger=CVS_AET \\\n",
        "--test_mode=True --bert_type=bert-base-cased \\\n",
        "--batch_size=16 --n_epochs=5 --lr=1e-5 --notarget\n",
        "\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))\n"
      ],
      "metadata": {
        "id": "4sdGXPVK_sWj",
        "outputId": "7bed06c6-5563-4754-c100-58499a23f5dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = False\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 47105 0 21174\n",
            "Length of train, eval_set: 47105 21174\n",
            "Before shuffling train[0] =  1036947014909616128 | After shuffling train[0] =  804007475368390656\n",
            "Downloading: 100% 570/570 [00:00<00:00, 442kB/s]\n",
            "Downloading: 100% 213k/213k [00:00<00:00, 1.82MB/s]\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 2945  | num_data= 47105\n",
            "65\n",
            "Eval_dataset: num_batches= 1324  | num_data= 21174\n",
            "67\n",
            "Dataset created\n",
            "Fri May  6 03:35:14 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    58W / 149W |    379MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Downloading: 100% 436M/436M [00:09<00:00, 45.1MB/s]\n",
            "Model created\n",
            "Fri May  6 03:35:27 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    59W / 149W |    379MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([28999, 768])\n",
            "108315652\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 24.730558395385742\n",
            "Train loss at 100: 14.575888633728027\n",
            "Train loss at 200: 14.929498672485352\n",
            "Train loss at 300: 9.613710403442383\n",
            "Train loss at 400: 22.006006240844727\n",
            "Train loss at 500: 17.591903686523438\n",
            "Train loss at 600: 15.620372772216797\n",
            "Train loss at 700: 10.080743789672852\n",
            "Train loss at 800: 9.927789688110352\n",
            "Train loss at 900: 14.007346153259277\n",
            "Train loss at 1000: 10.66773509979248\n",
            "Train loss at 1100: 11.86443042755127\n",
            "Train loss at 1200: 11.199695587158203\n",
            "Train loss at 1300: 15.263914108276367\n",
            "Train loss at 1400: 8.57630443572998\n",
            "Train loss at 1500: 11.4613676071167\n",
            "Train loss at 1600: 12.869590759277344\n",
            "Train loss at 1700: 8.821720123291016\n",
            "Train loss at 1800: 6.744391441345215\n",
            "Train loss at 1900: 8.177364349365234\n",
            "Train loss at 2000: 10.482271194458008\n",
            "Train loss at 2100: 8.043057441711426\n",
            "Train loss at 2200: 11.299094200134277\n",
            "Train loss at 2300: 4.282075881958008\n",
            "Train loss at 2400: 4.8602094650268555\n",
            "Train loss at 2500: 9.158198356628418\n",
            "Train loss at 2600: 9.764604568481445\n",
            "Train loss at 2700: 12.924483299255371\n",
            "Train loss at 2800: 9.88559627532959\n",
            "Train loss at 2900: 13.292116165161133\n",
            "EVALUATING:\n",
            "Valid_loss 26.29463117828542\n",
            "[[1143 5910    1  268]\n",
            " [1215 6885    4  404]\n",
            " [ 321 1192   18 1141]\n",
            " [ 321 1192   18 1141]]\n",
            "comment F1-score: 0.22146870761480333\n",
            "unrelated F1-score: 0.5813315320640015\n",
            "support F1-score: 0.013269443420567639\n",
            "refute F1-score: 0.4056167792392463\n",
            "Accu: 0.43388117502597523\n",
            "F1-Weighted 0.36303138466530355\n",
            "F1-Avg 0.3054216155846547\n",
            "[0/5]     train_loss: 11.94000valid_loss: 26.29463\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 13.953070640563965\n",
            "Train loss at 100: 4.851058483123779\n",
            "Train loss at 200: 12.330220222473145\n",
            "Train loss at 300: 5.483782768249512\n",
            "Train loss at 400: 14.930254936218262\n",
            "Train loss at 500: 13.527399063110352\n",
            "Train loss at 600: 9.681827545166016\n",
            "Train loss at 700: 7.010749340057373\n",
            "Train loss at 800: 7.627749443054199\n",
            "Train loss at 900: 11.603107452392578\n",
            "Train loss at 1000: 6.864062309265137\n",
            "Train loss at 1100: 6.691032886505127\n",
            "Train loss at 1200: 11.663020133972168\n",
            "Train loss at 1300: 13.628155708312988\n",
            "Train loss at 1400: 9.132013320922852\n",
            "Train loss at 1500: 8.869736671447754\n",
            "Train loss at 1600: 9.578824996948242\n",
            "Train loss at 1700: 6.087380886077881\n",
            "Train loss at 1800: 4.605218887329102\n",
            "Train loss at 1900: 4.42202091217041\n",
            "Train loss at 2000: 6.242546558380127\n",
            "Train loss at 2100: 4.414608955383301\n",
            "Train loss at 2200: 11.496833801269531\n",
            "Train loss at 2300: 3.6218721866607666\n",
            "Train loss at 2400: 3.9685463905334473\n",
            "Train loss at 2500: 6.590107440948486\n",
            "Train loss at 2600: 7.2367424964904785\n",
            "Train loss at 2700: 11.220163345336914\n",
            "Train loss at 2800: 9.091254234313965\n",
            "Train loss at 2900: 9.16323471069336\n",
            "EVALUATING:\n",
            "Valid_loss 39.79709597080496\n",
            "[[ 705 6532    5   80]\n",
            " [1368 6889   20  231]\n",
            " [ 247 1502  176  747]\n",
            " [ 247 1502  176  747]]\n",
            "comment F1-score: 0.1425826676104763\n",
            "unrelated F1-score: 0.5526009706012112\n",
            "support F1-score: 0.11544768776648083\n",
            "refute F1-score: 0.33370560643287916\n",
            "Accu: 0.402238594502692\n",
            "F1-Weighted 0.3280276259667376\n",
            "F1-Avg 0.2860842331027619\n",
            "[1/5]     train_loss: 9.19934valid_loss: 39.79710\n",
            "\n",
            "\n",
            "========= Beginning 3 epoch ==========\n",
            "Train loss at 0: 11.201217651367188\n",
            "Train loss at 100: 3.9524571895599365\n",
            "Train loss at 200: 9.216158866882324\n",
            "Train loss at 300: 4.044011116027832\n",
            "Train loss at 400: 16.37576675415039\n",
            "Train loss at 500: 9.191981315612793\n",
            "Train loss at 600: 6.224776268005371\n",
            "Train loss at 700: 5.653205871582031\n",
            "Train loss at 800: 7.665874004364014\n",
            "Train loss at 900: 11.149178504943848\n",
            "Train loss at 1000: 5.261189937591553\n",
            "Train loss at 1100: 9.123641967773438\n",
            "Train loss at 1200: 9.80400562286377\n",
            "Train loss at 1300: 8.60669231414795\n",
            "Train loss at 1400: 6.283390998840332\n",
            "Train loss at 1500: 6.222583293914795\n",
            "Train loss at 1600: 9.130117416381836\n",
            "Train loss at 1700: 6.17990255355835\n",
            "Train loss at 1800: 3.7051568031311035\n",
            "Train loss at 1900: 4.221429347991943\n",
            "Train loss at 2000: 7.1627349853515625\n",
            "Train loss at 2100: 3.208533763885498\n",
            "Train loss at 2200: 11.053893089294434\n",
            "Train loss at 2300: 3.8188014030456543\n",
            "Train loss at 2400: 2.8142282962799072\n",
            "Train loss at 2500: 5.9778618812561035\n",
            "Train loss at 2600: 7.4367451667785645\n",
            "Train loss at 2700: 7.094841957092285\n",
            "Train loss at 2800: 9.425200462341309\n",
            "Train loss at 2900: 6.659685134887695\n",
            "EVALUATING:\n",
            "Valid_loss 46.92457859753842\n",
            "[[ 482 6777    3   60]\n",
            " [1395 6884   16  213]\n",
            " [ 214 1678  157  623]\n",
            " [ 214 1678  157  623]]\n",
            "comment F1-score: 0.10013503687545443\n",
            "unrelated F1-score: 0.539392752203722\n",
            "support F1-score: 0.10449251247920133\n",
            "refute F1-score: 0.29730374612264376\n",
            "Accu: 0.3847171058845754\n",
            "F1-Weighted 0.3020658297315327\n",
            "F1-Avg 0.2603310119202554\n",
            "[2/5]     train_loss: 7.92535valid_loss: 46.92458\n",
            "\n",
            "\n",
            "========= Beginning 4 epoch ==========\n",
            "Train loss at 0: 11.286255836486816\n",
            "Train loss at 100: 4.093668460845947\n",
            "Train loss at 200: 9.54391098022461\n",
            "Train loss at 300: 5.268213272094727\n",
            "Train loss at 400: 7.782404899597168\n",
            "Train loss at 500: 9.93525505065918\n",
            "Train loss at 600: 6.219052791595459\n",
            "Train loss at 700: 4.060649394989014\n",
            "Train loss at 800: 4.795085906982422\n",
            "Train loss at 900: 10.44972038269043\n",
            "Train loss at 1000: 5.30875301361084\n",
            "Train loss at 1100: 6.135831356048584\n",
            "Train loss at 1200: 10.963987350463867\n",
            "Train loss at 1300: 7.731026649475098\n",
            "Train loss at 1400: 5.464545249938965\n",
            "Train loss at 1500: 5.578488349914551\n",
            "Train loss at 1600: 10.285539627075195\n",
            "Train loss at 1700: 6.032084941864014\n",
            "Train loss at 1800: 4.156113624572754\n",
            "Train loss at 1900: 4.072687149047852\n",
            "Train loss at 2000: 6.150338172912598\n",
            "Train loss at 2100: 4.132072925567627\n",
            "Train loss at 2200: 7.414126396179199\n",
            "Train loss at 2300: 2.97369647026062\n",
            "Train loss at 2400: 3.0410759449005127\n",
            "Train loss at 2500: 5.4670186042785645\n",
            "Train loss at 2600: 5.7699809074401855\n",
            "Train loss at 2700: 4.234674453735352\n",
            "Train loss at 2800: 9.281510353088379\n",
            "Train loss at 2900: 6.820646286010742\n",
            "EVALUATING:\n",
            "Valid_loss 51.407667041905334\n",
            "[[ 455 6781   14   72]\n",
            " [1502 6735   29  242]\n",
            " [ 184 1606  214  668]\n",
            " [ 184 1606  214  668]]\n",
            "comment F1-score: 0.09432984347465535\n",
            "unrelated F1-score: 0.5337612933903946\n",
            "support F1-score: 0.13617562838052819\n",
            "refute F1-score: 0.3091161499305877\n",
            "Accu: 0.38122225370737695\n",
            "F1-Weighted 0.30328439736158525\n",
            "F1-Avg 0.26834572879404145\n",
            "[3/5]     train_loss: 7.16960valid_loss: 51.40767\n",
            "\n",
            "\n",
            "========= Beginning 5 epoch ==========\n",
            "Train loss at 0: 8.903377532958984\n",
            "Train loss at 100: 2.8440821170806885\n",
            "Train loss at 200: 7.624208450317383\n",
            "Train loss at 300: 3.138676643371582\n",
            "Train loss at 400: 7.598164081573486\n",
            "Train loss at 500: 9.161441802978516\n",
            "Train loss at 600: 5.03031587600708\n",
            "Train loss at 700: 3.9855127334594727\n",
            "Train loss at 800: 3.9717190265655518\n",
            "Train loss at 900: 6.713599681854248\n",
            "Train loss at 1000: 5.469160556793213\n",
            "Train loss at 1100: 6.209023475646973\n",
            "Train loss at 1200: 8.26669692993164\n",
            "Train loss at 1300: 8.078969955444336\n",
            "Train loss at 1400: 5.362006187438965\n",
            "Train loss at 1500: 5.58750581741333\n",
            "Train loss at 1600: 8.298555374145508\n",
            "Train loss at 1700: 5.04911470413208\n",
            "Train loss at 1800: 5.074521541595459\n",
            "Train loss at 1900: 3.527843713760376\n",
            "Train loss at 2000: 4.928997039794922\n",
            "Train loss at 2100: 2.9803013801574707\n",
            "Train loss at 2200: 8.952611923217773\n",
            "Train loss at 2300: 3.039414167404175\n",
            "Train loss at 2400: 2.0807547569274902\n",
            "Train loss at 2500: 4.782211780548096\n",
            "Train loss at 2600: 6.2402873039245605\n",
            "Train loss at 2700: 4.519871711730957\n",
            "Train loss at 2800: 8.26319408416748\n",
            "Train loss at 2900: 7.1149187088012695\n",
            "EVALUATING:\n",
            "Valid_loss 58.74959503415848\n",
            "[[ 351 6910   14   47]\n",
            " [1461 6799   41  207]\n",
            " [ 156 1621  232  663]\n",
            " [ 156 1621  232  663]]\n",
            "comment F1-score: 0.0743171712894347\n",
            "unrelated F1-score: 0.5341136729643741\n",
            "support F1-score: 0.1454089627076152\n",
            "refute F1-score: 0.31185324553151456\n",
            "Accu: 0.37994710494002076\n",
            "F1-Weighted 0.29801615557651323\n",
            "F1-Avg 0.2664232631232346\n",
            "[4/5]     train_loss: 6.73326valid_loss: 58.74960\n",
            "/content/gdrive/MyDrive/NLP Stance Detection/tWT_WT/saves/twtwt_CVS_AET_notarget\n",
            "Total time taken (mins):  77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "start_time = time.time()\n",
        "\n",
        "!python /content/gdrive/MyDrive/NLP\\ Stance\\ Detection/tWT_WT/train.py \\\n",
        "--dataset_path=\"dataset/data_new.json\" \\\n",
        "--seed=4214 \\\n",
        "--cross_valid_num=4 \\\n",
        "--target_merger=CVS_AET \\\n",
        "--test_mode=True --bert_type=bert-base-cased \\\n",
        "--batch_size=16 --n_epochs=2 --lr=1e-5\n",
        "\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))\n"
      ],
      "metadata": {
        "id": "kY5MH9DQB0XK",
        "outputId": "e66d34ba-037d-418c-f7ae-001c225fb427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = True\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 47105 0 21174\n",
            "Length of train, eval_set: 47105 21174\n",
            "Before shuffling train[0] =  1036947014909616128 | After shuffling train[0] =  804007475368390656\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 2945  | num_data= 47105\n",
            "68\n",
            "Eval_dataset: num_batches= 1324  | num_data= 21174\n",
            "70\n",
            "Dataset created\n",
            "Fri May  6 05:09:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    58W / 149W |    383MiB / 11441MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Model created\n",
            "Fri May  6 05:09:49 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    58W / 149W |    383MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([28999, 768])\n",
            "108315652\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 23.51035499572754\n",
            "Train loss at 100: 15.274256706237793\n",
            "Train loss at 200: 15.439114570617676\n",
            "Train loss at 300: 10.184967041015625\n",
            "Train loss at 400: 19.569456100463867\n",
            "Train loss at 500: 15.17954158782959\n",
            "Train loss at 600: 14.129507064819336\n",
            "Train loss at 700: 11.553966522216797\n",
            "Train loss at 800: 11.374835968017578\n",
            "Train loss at 900: 11.606046676635742\n",
            "Train loss at 1000: 11.64731502532959\n",
            "Train loss at 1100: 11.498720169067383\n",
            "Train loss at 1200: 14.541149139404297\n",
            "Train loss at 1300: 13.458841323852539\n",
            "Train loss at 1400: 8.669512748718262\n",
            "Train loss at 1500: 11.770113945007324\n",
            "Train loss at 1600: 12.396671295166016\n",
            "Train loss at 1700: 9.718582153320312\n",
            "Train loss at 1800: 7.9722490310668945\n",
            "Train loss at 1900: 8.442177772521973\n",
            "Train loss at 2000: 10.128908157348633\n",
            "Train loss at 2100: 9.001888275146484\n",
            "Train loss at 2200: 11.324976921081543\n",
            "Train loss at 2300: 4.783652305603027\n",
            "Train loss at 2400: 4.744299411773682\n",
            "Train loss at 2500: 9.144881248474121\n",
            "Train loss at 2600: 8.912919044494629\n",
            "Train loss at 2700: 12.583775520324707\n",
            "Train loss at 2800: 11.292571067810059\n",
            "Train loss at 2900: 14.623824119567871\n",
            "EVALUATING:\n",
            "Valid_loss 21.910816125999403\n",
            "[[1579 5355  158  230]\n",
            " [1258 6772  221  257]\n",
            " [ 232 1220 1093  127]\n",
            " [ 437  563  119 1553]]\n",
            "comment F1-score: 0.291651274473587\n",
            "unrelated F1-score: 0.6041573735391204\n",
            "support F1-score: 0.5127844241144734\n",
            "refute F1-score: 0.641868154577392\n",
            "Accu: 0.5193633701709643\n",
            "F1-Weighted 0.4893205467096961\n",
            "F1-Avg 0.5126153066761432\n",
            "[0/2]     train_loss: 11.60692valid_loss: 21.91082\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 15.851888656616211\n",
            "Train loss at 100: 5.414376258850098\n",
            "Train loss at 200: 12.418107032775879\n",
            "Train loss at 300: 5.157414436340332\n",
            "Train loss at 400: 15.99532699584961\n",
            "Train loss at 500: 10.521425247192383\n",
            "Train loss at 600: 6.586715221405029\n",
            "Train loss at 700: 7.082324028015137\n",
            "Train loss at 800: 5.786448955535889\n",
            "Train loss at 900: 10.518616676330566\n",
            "Train loss at 1000: 9.04530143737793\n",
            "Train loss at 1100: 8.123527526855469\n",
            "Train loss at 1200: 8.871923446655273\n",
            "Train loss at 1300: 7.227985382080078\n",
            "Train loss at 1400: 4.833338260650635\n",
            "Train loss at 1500: 8.730517387390137\n",
            "Train loss at 1600: 7.891696929931641\n",
            "Train loss at 1700: 4.7255330085754395\n",
            "Train loss at 1800: 4.595448970794678\n",
            "Train loss at 1900: 5.032944679260254\n",
            "Train loss at 2000: 5.756306171417236\n",
            "Train loss at 2100: 2.9595885276794434\n",
            "Train loss at 2200: 9.819295883178711\n",
            "Train loss at 2300: 2.835726737976074\n",
            "Train loss at 2400: 1.7327274084091187\n",
            "Train loss at 2500: 6.467915058135986\n",
            "Train loss at 2600: 5.274751663208008\n",
            "Train loss at 2700: 8.644551277160645\n",
            "Train loss at 2800: 5.375282287597656\n",
            "Train loss at 2900: 9.475800514221191\n",
            "EVALUATING:\n",
            "Valid_loss 30.347693033809026\n",
            "[[1128 5974  107  113]\n",
            " [1310 6855  167  176]\n",
            " [ 266 1304 1024   78]\n",
            " [ 365  931   86 1290]]\n",
            "comment F1-score: 0.21711096140891156\n",
            "unrelated F1-score: 0.5816222637026982\n",
            "support F1-score: 0.504930966469428\n",
            "refute F1-score: 0.595980595980596\n",
            "Accu: 0.486303957683952\n",
            "F1-Weighted 0.4477077724513588\n",
            "F1-Avg 0.4749111968904084\n",
            "[1/2]     train_loss: 7.49736valid_loss: 30.34769\n",
            "/content/gdrive/MyDrive/NLP Stance Detection/tWT_WT/saves/twtwt_CVS_AET_notarget\n",
            "Total time taken (mins):  32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "232fUdKIxe0G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}