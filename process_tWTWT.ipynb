{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mangalm96/explainablenlp-info259/blob/main/process_tWTWT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fceecef",
      "metadata": {
        "id": "3fceecef"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "import re\n",
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed0b8a7",
      "metadata": {
        "id": "bed0b8a7"
      },
      "outputs": [],
      "source": [
        "EMOJI_PATTERN = re.compile(\"[\"\n",
        "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "         u\"\\U00002702-\\U000027B0\"\n",
        "         u\"\\U000024C2-\\U0001F251\"\n",
        "         \"]+\", flags=re.UNICODE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4444dc1f",
      "metadata": {
        "id": "4444dc1f",
        "outputId": "aa3225a8-c0a3-42b3-cae6-0b51d806463c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/siqiwu/opt/anaconda3/lib/python3.7/site-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n",
            "Reading twitter - 1grams ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/siqiwu/opt/anaconda3/lib/python3.7/site-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
          ]
        }
      ],
      "source": [
        "text_processor = TextPreProcessor(\n",
        "    normalize=['url', 'email', 'percent', 'money', 'phone',\n",
        "        'time', 'url', 'date', 'number'],\n",
        "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "        'emphasis', 'censored'},\n",
        "\n",
        "    fix_html=True,\n",
        "    segmenter=\"twitter\",\n",
        "    corrector=\"twitter\",\n",
        "\n",
        "    unpack_hashtags=True,\n",
        "    unpack_contractions=True,\n",
        "    spell_correct_elong=True,\n",
        "\n",
        "    tokenizer=SocialTokenizer(lowercase=False).tokenize,\n",
        "    dicts=[emoticons]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8e1c418",
      "metadata": {
        "id": "e8e1c418"
      },
      "outputs": [],
      "source": [
        "REMOVE_TAGS = [\n",
        "    \"<emphasis>\", \"<kiss>\", \"<repeated>\", \"<laugh>\", \"<allcaps>\",\n",
        "    \"</allcaps>\", \"<angel>\", \"<elongated>\", \"<tong>\", \"<annoyed>\",\n",
        "    \"<censored>\", \"<happy>\", \"<percent>\", \"<wink>\",\n",
        "    \"<headdesk>\", \"<surprise>\", \"<date>\", \"<time>\", \"<url>\",\n",
        "    \"<sad>\", \"<email>\", \"<phone>\", \"<hashtag>\", \"</hashtag>\"\n",
        "    ]\n",
        "\n",
        "ADD_TO_GLOVE = [\"<number>\", \"<money>\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0e0dba",
      "metadata": {
        "id": "fa0e0dba"
      },
      "outputs": [],
      "source": [
        "REMOVE_PUNCTUATIONS = [\"!\", \"@\", \"#\", \"$\", \"%\", \"^\", \"&\", \"*\", \"(\", \")\", \"-\", \"+\", \"_\", \"=\", \"{\", \"}\", \"[\", \"]\", \":\", \";\", \"'\", '\"', \",\", \".\", \"?\", \"/\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2846780",
      "metadata": {
        "id": "f2846780"
      },
      "outputs": [],
      "source": [
        "# Try removing punctuations as well\n",
        "\n",
        "def pre_process_single(tweet, t_id):\n",
        "    tweet_toked_text = []\n",
        "    de_emojified_text = tweet.encode('ascii', 'ignore').decode('ascii')\n",
        "    de_emojified_text = re.sub(r\"\\$\", \" $ \", de_emojified_text)\n",
        "    company_normalize_text = EMOJI_PATTERN.sub(r' ', de_emojified_text)\n",
        "\n",
        "    tokens = text_processor.pre_process_doc(company_normalize_text)\n",
        "    for token in tokens:\n",
        "        if token in REMOVE_TAGS:\n",
        "            continue\n",
        "        if token in REMOVE_PUNCTUATIONS: #remove punctuations\n",
        "            continue\n",
        "        tweet_toked_text.append(str(token))\n",
        "\n",
        "    return tweet_toked_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1656e64b",
      "metadata": {
        "id": "1656e64b"
      },
      "outputs": [],
      "source": [
        "id2text = {}\n",
        "tweet_acquired = 0\n",
        "tweet_valid = 0\n",
        "tweet_invalid = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2394358f",
      "metadata": {
        "id": "2394358f"
      },
      "outputs": [],
      "source": [
        "for fil in glob.glob(\"/Users/siqiwu/Documents/Berkeley/Info-NLP/project/bias-stance/data/wtwt/scrapped_full/*\"):\n",
        "    fo = open(fil, \"r\")\n",
        "    full_tweet = json.load(fo)\n",
        "    fo.close()\n",
        "    tweet_acquired = tweet_acquired + 1\n",
        "    if \"data\" not in full_tweet:\n",
        "        tweet_invalid = tweet_invalid + 1\n",
        "        continue\n",
        "    tweet_valid = tweet_valid + 1\n",
        "    tweet_id = full_tweet[\"data\"][0][\"id\"]\n",
        "    txt = pre_process_single(full_tweet[\"data\"][0][\"text\"], tweet_id)\n",
        "    if len(txt) > 0 and txt != [\"<user>\"]:\n",
        "        id2text[tweet_id] = txt\n",
        "    else: \n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb338168",
      "metadata": {
        "id": "fb338168",
        "outputId": "530ea3d0-a3a7-449d-d7d4-cc3b784b2ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the number of tweet acquired is: {50208}\n",
            "the number of invalid tweet is: {7190}\n",
            "the number of valid tweet is: {43018}\n"
          ]
        }
      ],
      "source": [
        "print(f'the number of tweet acquired is:',{tweet_acquired})\n",
        "print(f'the number of invalid tweet is:',{tweet_invalid})\n",
        "print(f'the number of valid tweet is:',{tweet_valid})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11d760fb",
      "metadata": {
        "id": "11d760fb",
        "outputId": "ac4b8693-9593-4695-a9a7-8db8ce47b7e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43010"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_keys = id2text.keys()\n",
        "len(all_keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c28d3c11",
      "metadata": {
        "id": "c28d3c11"
      },
      "outputs": [],
      "source": [
        "fo = open(\"/Users/siqiwu/Documents/Berkeley/Info-NLP/project/stance-dataset/dataset/wtwt_new.json\", \"r\")\n",
        "wtwt = json.load(fo)\n",
        "fo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3df772f",
      "metadata": {
        "id": "d3df772f"
      },
      "outputs": [],
      "source": [
        "wtwt_obtained = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce94e7d5",
      "metadata": {
        "id": "ce94e7d5"
      },
      "outputs": [],
      "source": [
        "merger2target = json.load(open('/Users/siqiwu/Documents/Berkeley/Info-NLP/project/bias-stance/data/wtwt/merger2target.json'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f5cbbf",
      "metadata": {
        "id": "92f5cbbf"
      },
      "outputs": [],
      "source": [
        "for data in wtwt:\n",
        "    if data[\"tweet_id\"] in all_keys:\n",
        "        d = data.copy()\n",
        "        d[\"target\"] = merger2target[d[\"merger\"]].split()\n",
        "        d[\"text\"] = id2text[data[\"tweet_id\"]]\n",
        "        d[\"merger\"] = d[\"merger\"][4:] if \"NEG_\" in d[\"merger\"] else d[\"merger\"]\n",
        "        assert d[\"merger\"] in ['CVS_AET', 'CI_ESRX', 'AET_HUM', 'ANTM_CI', 'DIS_FOX']\n",
        "        wtwt_obtained.append(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0168aaab",
      "metadata": {
        "id": "0168aaab"
      },
      "outputs": [],
      "source": [
        "fo = open(\"/Users/siqiwu/Documents/Berkeley/Info-NLP/project/stance-dataset/dataset/data_twtwt.json\", \"w+\")\n",
        "json.dump(wtwt_obtained, fo, indent=2)\n",
        "fo.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d99beb9d",
      "metadata": {
        "id": "d99beb9d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "process_tWTWT.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}