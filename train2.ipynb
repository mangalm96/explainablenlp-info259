{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mangalm96/explainablenlp-info259/blob/main/train2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyEizW0NPJVc",
        "outputId": "613e0389-f68e-407f-f3ce-a1ad2c96db42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-_EYEUkPMpX",
        "outputId": "d68dd57f-1884-43d3-da0c-ea575b33c66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "data = open(\"/content/gdrive/MyDrive/NLP Stance Detection/Code_Kaushal/data/wtwt/data.json\")\n",
        "data_list = json.load(data)"
      ],
      "metadata": {
        "id": "9C83n8RAbarx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stance_dict = dict()\n",
        "for record in data_list:\n",
        "  stance = record[\"stance\"]\n",
        "  stance_dict[stance] = stance_dict.get(stance, 0) + 1"
      ],
      "metadata": {
        "id": "aE6DodHacD7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stance_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRxk-BMCcUk-",
        "outputId": "8c047f92-3e3e-426f-df92-32f19854b1bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'comment': 18087, 'refute': 3791, 'support': 5951, 'unrelated': 16169}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking traintest dev json\n",
        "train_dt = open(\"/content/gdrive/MyDrive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CI_ESRX_target/train.json\")\n",
        "train_dt_list = json.load(train_dt)\n"
      ],
      "metadata": {
        "id": "8c4AiJZpfBd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dt_list['data'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imDlVBprgMuO",
        "outputId": "942f5f7c-618b-464f-fbb2-b52289205d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27130"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targ_dict_tr = dict()\n",
        "for record in train_dt_list['data']:\n",
        "  stance = record[\"merger\"]\n",
        "  targ_dict_tr[stance] = targ_dict_tr.get(stance, 0) + 1"
      ],
      "metadata": {
        "id": "jUIBvXysfRom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targ_dict_tr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ra1gUFWgk-F",
        "outputId": "202739c3-efc5-4f2d-e257-bd653cdb6ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AET_HUM': 6996, 'ANTM_CI': 9927, 'CVS_AET': 10207}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking traintest dev json\n",
        "train_dt = open(\"/content/gdrive/MyDrive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CVS_AET_target/train.json\")\n",
        "train_dt_list = json.load(train_dt)\n",
        "\n",
        "targ_dict_tr = dict()\n",
        "for record in train_dt_list['data']:\n",
        "  stance = record[\"merger\"]\n",
        "  targ_dict_tr[stance] = targ_dict_tr.get(stance, 0) + 1\n",
        "\n",
        "targ_dict_tr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh6nPC1IhSgQ",
        "outputId": "82c9fda8-6a99-4440-e2d5-3064ea69d943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AET_HUM': 6996, 'ANTM_CI': 6094, 'CI_ESRX': 2226}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking traintest dev json\n",
        "train_dt = open(\"/content/gdrive/MyDrive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CI_ESRX_target/test.json\")\n",
        "train_dt_list = json.load(train_dt)\n",
        "\n",
        "targ_dict_tr = dict()\n",
        "for record in train_dt_list['data']:\n",
        "  stance = record[\"merger\"]\n",
        "  targ_dict_tr[stance] = targ_dict_tr.get(stance, 0) + 1\n",
        "\n",
        "targ_dict_tr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOjQdrVVhcaS",
        "outputId": "5a476c4f-6c8d-4249-c839-7276cfee4c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CI_ESRX': 2226}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CVS_AET_dict=dict()\n",
        "CI_ESRX_dict = dict()\n",
        "ANTM_CI_dict = dict()\n",
        "AET_HUM_dict = dict()\n",
        "DIS_FOXA_dict = dict()\n",
        "for record in data_list:\n",
        "  stance = record[\"stance\"]\n",
        "  merger = record[\"merger\"]\n",
        "  if merger == 'CVS_AET':\n",
        "    CVS_AET_dict[stance] = CVS_AET_dict.get(stance, 0) + 1\n",
        "  elif merger == 'CI_ESRX':\n",
        "    CI_ESRX_dict[stance] = CI_ESRX_dict.get(stance, 0) + 1\n",
        "  elif merger == 'ANTM_CI':\n",
        "    ANTM_CI_dict[stance] = ANTM_CI_dict.get(stance, 0) + 1\n",
        "  elif merger == 'AET_HUM':\n",
        "    AET_HUM_dict[stance] = AET_HUM_dict.get(stance, 0) + 1\n",
        "  else:\n",
        "    DIS_FOXA_dict[stance] = DIS_FOXA_dict.get(stance, 0) + 1\n"
      ],
      "metadata": {
        "id": "Qj3FVrLDlzMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(CVS_AET_dict)\n",
        "print(CI_ESRX_dict)\n",
        "print(ANTM_CI_dict)\n",
        "print(AET_HUM_dict)\n",
        "print(DIS_FOXA_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY4_HsKKoKk7",
        "outputId": "40613550-b091-45ad-b3eb-5cca25610620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'support': 2225, 'comment': 4899, 'unrelated': 2636, 'refute': 447}\n",
            "{'support': 688, 'unrelated': 461, 'comment': 852, 'refute': 225}\n",
            "{'support': 881, 'unrelated': 4444, 'comment': 2811, 'refute': 1791}\n",
            "{'support': 937, 'comment': 2538, 'unrelated': 2523, 'refute': 998}\n",
            "{'comment': 6987, 'unrelated': 6105, 'support': 1220, 'refute': 330}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## installs and imports"
      ],
      "metadata": {
        "id": "k48T2Vi4o3SG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==3.5.0\n",
        "!pip install wandb==0.9.4\n",
        "!pip install scikit-learn==0.23.1\n",
        "!pip install scipy==1.5.0\n",
        "!pip install ekphrasis==0.5.1\n",
        "!pip install emoji\n",
        "import time"
      ],
      "metadata": {
        "id": "x6tCpuzVPWLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4dd98ae-0490-42db-9a56-ae24eebcbcaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.5.0\n",
            "  Downloading transformers-3.5.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.17.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2019.12.20)\n",
            "Collecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 38.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.6.0)\n",
            "Collecting tokenizers==0.9.3\n",
            "  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 34.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.0) (3.0.7)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.0) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (1.1.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.49 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.0\n",
            "Collecting wandb==0.9.4\n",
            "  Downloading wandb-0.9.4-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (1.15.0)\n",
            "Collecting gql==0.2.0\n",
            "  Downloading gql-0.2.0.tar.gz (18 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (5.4.8)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (7.352.0)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (2.8.2)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (3.13)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "  Downloading sentry_sdk-1.5.8-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 36.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.9.4) (2.23.0)\n",
            "Collecting watchdog>=0.8.3\n",
            "  Downloading watchdog-2.1.7-py3-none-manylinux2014_x86_64.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting graphql-core<2,>=0.5.0\n",
            "  Downloading graphql-core-1.1.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from gql==0.2.0->wandb==0.9.4) (2.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb==0.9.4) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->wandb==0.9.4) (3.0.4)\n",
            "Building wheels for collected packages: gql, graphql-core, subprocess32\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-py3-none-any.whl size=7638 sha256=af8993387c9d19d28a448b4d206d38ab6d9cbe70398f4350a7f8da5446d5f8fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/9a/56/5456fd32264a8fc53eefcb2f74e24e99a7ef4eb40a9af5c905\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-py3-none-any.whl size=104649 sha256=57bb056a92f24e9a38bd6ab36e58f636c6da0113c245060f6470f55a352b9377\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/fd/8c/a20dd591c1a554070cc33fb58042867e6ac1c85395abe2e57a\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=71b4f05f52e1818f3aaadd945c72689eb81ebac8e4776e5d1048aab78ecc8b02\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "Successfully built gql graphql-core subprocess32\n",
            "Installing collected packages: smmap, graphql-core, gitdb, watchdog, subprocess32, shortuuid, sentry-sdk, gql, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.27 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 gql-0.2.0 graphql-core-1.1 sentry-sdk-1.5.8 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.9.4 watchdog-2.1.7\n",
            "Collecting scikit-learn==0.23.1\n",
            "  Downloading scikit_learn-0.23.1-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1) (1.4.1)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.1 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.1\n",
            "Collecting scipy==1.5.0\n",
            "  Downloading scipy-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.5.0) (1.21.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.5.0\n",
            "Collecting ekphrasis==0.5.1\n",
            "  Downloading ekphrasis-0.5.1.tar.gz (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (4.63.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting ujson\n",
            "  Downloading ujson-5.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (3.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (3.2.5)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1) (1.21.5)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis==0.5.1) (0.2.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis==0.5.1) (3.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->ekphrasis==0.5.1) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->ekphrasis==0.5.1) (1.15.0)\n",
            "Building wheels for collected packages: ekphrasis\n",
            "  Building wheel for ekphrasis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ekphrasis: filename=ekphrasis-0.5.1-py3-none-any.whl size=82842 sha256=12b406f856a72559e624c567100d62a0946fd446e6070c3f5aee6a9e20803420\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/ec/0d/12659e32faf780546945d0120f2c8410eb3efb7426731da88f\n",
            "Successfully built ekphrasis\n",
            "Installing collected packages: ujson, ftfy, colorama, ekphrasis\n",
            "Successfully installed colorama-0.4.4 ekphrasis-0.5.1 ftfy-6.1.1 ujson-5.2.0\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 4.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=5fda7518d50b5fce647194d28c267b913a767eb7829e9104dd90a303df14a1a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31CqjrIYbGEt",
        "outputId": "aa439929-af96-4d02-8bc4-a4732e2e8a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 6.8 kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automated run"
      ],
      "metadata": {
        "id": "ZhKFpeT30rW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gdrive/My\\ Drive/NLP\\ Project/bias-stance/bertloader.py --target_merger=CI_ESRX --bert_type=vinai/bertweet-base --dataset_name=wtwt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRjwnQYXneXq",
        "outputId": "d5a43347-a3ed-49be-d33c-ca0f397e0178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = True\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 27130 0 2226\n",
            "Length of train, eval_set: 27130 2226\n",
            "Before shuffling train[0] =  944165633889095681 | After shuffling train[0] =  831878268378816513\n",
            "/content/gdrive/.shortcut-targets-by-id/1cqRKadLOmUTbjUjku8ixQublzk8n8F2_/NLP Project/bias-stance/saves/wtwt_CI_ESRX_target\n",
            "1. Type of train dataset\n",
            "27130\n",
            "{'tweet_id': '831878268378816513', 'merger': 'ANTM_CI', 'stance': 'support', 'text': ['Anthem', 'Sues', 'Cigna', 'To', 'Prevent', 'Termination', 'Of', 'Their', '$', '<number>', 'Billion', 'Dollar', 'Merger', 'Deal', 'anthem', 'cigna', 'merger', 'reuters'], 'target': 'Anthem Cigna'}\n",
            "Downloading: 100% 558/558 [00:00<00:00, 437kB/s]\n",
            "Downloading: 100% 843k/843k [00:00<00:00, 926kB/s]\n",
            "Downloading: 100% 1.08M/1.08M [00:01<00:00, 992kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1696  | num_data= 27130\n",
            "97\n",
            "Eval_dataset: num_batches= 140  | num_data= 2226\n",
            "97\n",
            "Train_dataset Size = 1696 Eval_dataset Size = 140\n",
            "1696\n",
            "(tensor([[    0, 22250,     3, 12691,     4,  2993,  2336,   144, 22250,   144,\n",
            "             3,   144,     3,   144,  7444, 22250, 13606,  9492,  7761,     2,\n",
            "             2, 17336, 42182,   880,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,     3,  9568,  1163,  5061,   633,    52,  4978,  4749,     9,\n",
            "         17336,  2993,     3,  7051,  4521,     2,     2, 17336, 42182,   880,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0, 12421, 55119,   708,  2047,  8536, 14659,     3,     7,     3,\n",
            "             7,     3,     2,     2,   327,  1828,   880,  7110,  1706,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,     3,  5763, 57274,   348,   619,   490, 17336, 33494, 10523,\n",
            "            22,   104,     3, 22507,   152,    31,    11,    26, 12446,  1278,\n",
            "            19,  2351,     4,     2,     2,   327,  1828,   880,  7110,  1706,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,   125,     3,    55, 17336,    32, 29541,     7,    11,  1330,\n",
            "            34,     3,    15,     3,  6797,     9, 17336,    34,   927,  9984,\n",
            "          7789, 23538,  4918,   144,   144,     2,     2, 17336, 42182,   880,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,   196,    64,     8,   307,     8,   152,    46,    26,  2784,\n",
            "            21,    26,   695,     7, 29769, 10473,     3,     2,     2, 38424,\n",
            "         24517,  1960,   327,  1828,   880,     2,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,   122,   144, 64001,    16,     3,    24,    66,     3,   144,\n",
            "         54266,   151,    32,    16,     6,   960,    15,     3,   144, 29769,\n",
            "             3,   144,     3,     3,     2,     2, 38424, 24517,  1960,   327,\n",
            "          1828,   880,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,   165,   158,     6,   127, 17336,    13, 29769,     3,   810,\n",
            "           271,    19,     3,    21,     2,     2, 38424, 24517,  1960,   327,\n",
            "          1828,   880,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    0,   295, 12873,   317,    22,     8,    43,     9,  2650,    18,\n",
            "             7,  2650,    18,    12,   295,  6347,   317,    22,     8,    43,\n",
            "             9,   560,    18,     7,   560,    18,    12,   295, 22716,   317,\n",
            "            22,     8,    43,     9, 29541,    18,     7, 29541,    18,    12,\n",
            "           295, 16203,   317,    22,  1418,   361, 64001,     2,     2, 17336,\n",
            "         42182,   880,     2],\n",
            "        [    0,  2780,  2116,    70, 12446,  4127,  4783,    19, 17336,     4,\n",
            "         17336,    34,     3, 23536,  4647,     9,   297,   217,   223,     2,\n",
            "             2, 17336, 42182,   880,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1]], device='cuda:0'), tensor([1, 3, 1, 0, 0, 2, 0, 1, 1, 0], device='cuda:0'), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'))\n",
            "Sun Apr 10 00:05:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    59W / 149W |    347MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gdrive/My\\ Drive/NLP\\ Project/bias-stance/train.py --dataset_name=wtwt --target_merger=CI_ESRX --test_mode=True --bert_type=vinai/bertweet-base"
      ],
      "metadata": {
        "id": "F9Wk-jYCPRlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python gdrive/My\\ Drive/NLP\\ Project/bias-stance/train.py --dataset_name=wtwt --target_merger=CI_ESRX --test_mode=True --bert_type=vinai/bertweet-base --notarget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyGwQo0v61HO",
        "outputId": "b136a55f-ac45-4b66-a87b-8452fb0b16d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = False\n",
            "++++++++++++++++++++++\n",
            "Traceback (most recent call last):\n",
            "  File \"gdrive/My Drive/NLP Project/bias-stance/train.py\", line 8, in <module>\n",
            "  File \"/content/gdrive/.shortcut-targets-by-id/1cqRKadLOmUTbjUjku8ixQublzk8n8F2_/NLP Project/bias-stance/bertloader.py\", line 5, in <module>\n",
            "    from transformers import AutoTokenizer\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/__init__.py\", line 22, in <module>\n",
            "    from .integrations import (  # isort:skip\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/integrations.py\", line 81, in <module>\n",
            "    from .file_utils import is_torch_tpu_available  # noqa: E402\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\", line 59, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\", line 51, in <module>\n",
            "    from ._api.v2 import compat\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/__init__.py\", line 37, in <module>\n",
            "    from . import v1\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 30, in <module>\n",
            "    from . import compat\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 37, in <module>\n",
            "    from . import v1\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\", line 47, in <module>\n",
            "    from tensorflow._api.v2.compat.v1 import lite\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py\", line 9, in <module>\n",
            "    from . import experimental\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py\", line 8, in <module>\n",
            "    from . import authoring\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.lite.python.authoring.authoring import compatible\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/authoring/authoring.py\", line 43, in <module>\n",
            "    from tensorflow.lite.python import convert\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py\", line 29, in <module>\n",
            "    from tensorflow.lite.python import util\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/util.py\", line 51, in <module>\n",
            "    from jax import xla_computation as _xla_computation\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/__init__.py\", line 135, in <module>\n",
            "    from jax import nn as nn\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/nn/__init__.py\", line 21, in <module>\n",
            "    from jax._src.nn.functions import (\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/nn/functions.py\", line 29, in <module>\n",
            "    from jax.scipy.special import expit\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/scipy/__init__.py\", line 19, in <module>\n",
            "    from jax.scipy import signal as signal\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/scipy/signal.py\", line 17, in <module>\n",
            "    from jax._src.scipy.signal import (\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/scipy/signal.py\", line 15, in <module>\n",
            "    import scipy.signal as osp_signal\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/signal/__init__.py\", line 307, in <module>\n",
            "    from ._peak_finding import *\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/signal/_peak_finding.py\", line 8, in <module>\n",
            "    from scipy.stats import scoreatpercentile\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/__init__.py\", line 388, in <module>\n",
            "    from .stats import *\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py\", line 180, in <module>\n",
            "    from . import distributions\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/distributions.py\", line 12, in <module>\n",
            "    from . import _discrete_distns\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/_discrete_distns.py\", line 703, in <module>\n",
            "    planck = planck_gen(a=0, name='planck', longname='A discrete exponential ')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/_distn_infrastructure.py\", line 2880, in __init__\n",
            "    locscale_out='loc, 1')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scipy/stats/_distn_infrastructure.py\", line 701, in _construct_argparser\n",
            "    exec(parse_arg_template % dct, ns)\n",
            "  File \"<string>\", line 2, in <module>\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "byrwwrQA2vaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## individual script run"
      ],
      "metadata": {
        "id": "zgb8EqJGy0AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# target_merger=['CVS_AET', 'ANTM_CI', 'AET_HUM', 'CI_ESRX']"
      ],
      "metadata": {
        "id": "-fDB-gVTqy8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CVS_AET"
      ],
      "metadata": {
        "id": "zOhwtfGlo9en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='CVS_AET' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=5 --lr=1e-5\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))\n"
      ],
      "metadata": {
        "id": "TdqK-rby0tkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='CVS_AET' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=2 --lr=1e-5 --notarget\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01hk1RDMP_fs",
        "outputId": "81f08cad-59fe-45c5-bee5-08ee163a67d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = False\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 19149 0 10207\n",
            "Length of train, eval_set: 19149 10207\n",
            "Before shuffling train[0] =  971761970117357568 | After shuffling train[0] =  799735673758461952\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_CVS_AET_notarget\n",
            "1. Type of train dataset\n",
            "Length of train: 19149\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1197  | num_data= 19149\n",
            "81\n",
            "Eval_dataset: num_batches= 638  | num_data= 10207\n",
            "91\n",
            "Dataset created\n",
            "Mon Apr 11 05:40:44 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    59W / 149W |    341MiB / 11441MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Model created\n",
            "Mon Apr 11 05:40:49 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    59W / 149W |    341MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 21.599384307861328\n",
            "Train loss at 100: 16.52383804321289\n",
            "Train loss at 200: 21.635372161865234\n",
            "Train loss at 300: 12.12059211730957\n",
            "Train loss at 400: 13.736662864685059\n",
            "Train loss at 500: 11.898272514343262\n",
            "Train loss at 600: 5.044932842254639\n",
            "Train loss at 700: 14.209421157836914\n",
            "Train loss at 800: 7.086994647979736\n",
            "Train loss at 900: 4.553409576416016\n",
            "Train loss at 1000: 4.541085243225098\n",
            "Train loss at 1100: 8.943649291992188\n",
            "EVALUATING:\n",
            "Valid_loss 12.346660951835608\n",
            "[[3363 1214  226   96]\n",
            " [ 644 1886   40   66]\n",
            " [ 454  262 1462   47]\n",
            " [ 160   11   12  264]]\n",
            "comment F1-score: 0.7065126050420169\n",
            "unrelated F1-score: 0.6277250790480945\n",
            "support F1-score: 0.737452711223203\n",
            "refute F1-score: 0.5739130434782608\n",
            "Accu: 0.6833545605956697\n",
            "F1-Weighted 0.687102965942787\n",
            "F1-Avg 0.6614008596978938\n",
            "[0/2]     train_loss: 10.97396 valid_loss: 12.34666\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 4.5722527503967285\n",
            "Train loss at 100: 8.908360481262207\n",
            "Train loss at 200: 16.55978012084961\n",
            "Train loss at 300: 7.3852949142456055\n",
            "Train loss at 400: 7.6364593505859375\n",
            "Train loss at 500: 10.466428756713867\n",
            "Train loss at 600: 3.0604734420776367\n",
            "Train loss at 700: 15.04321002960205\n",
            "Train loss at 800: 7.034690856933594\n",
            "Train loss at 900: 3.0528275966644287\n",
            "Train loss at 1000: 2.411341667175293\n",
            "Train loss at 1100: 7.368627548217773\n",
            "EVALUATING:\n",
            "Valid_loss 12.708086812757774\n",
            "[[3319 1309  197   74]\n",
            " [ 570 1977   50   39]\n",
            " [ 482  276 1434   33]\n",
            " [ 165   16    8  258]]\n",
            "comment F1-score: 0.7035506094329622\n",
            "unrelated F1-score: 0.6363051174766657\n",
            "support F1-score: 0.7327542156361778\n",
            "refute F1-score: 0.6063454759106933\n",
            "Accu: 0.6846281963358479\n",
            "F1-Weighted 0.6882932578429655\n",
            "F1-Avg 0.6697388546141247\n",
            "[1/2]     train_loss: 7.33911 valid_loss: 12.70809\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_CVS_AET_notarget\n",
            "Total time taken (mins):  14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ANTM_CI"
      ],
      "metadata": {
        "id": "ONTkE_dipF-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='ANTM_CI' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=5 --lr=1e-5\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPAovL_-tFS2",
        "outputId": "271b1442-9e0c-4a45-9612-e1bfceff5bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = True\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 19429 0 9927\n",
            "Length of train, eval_set: 19429 9927\n",
            "Before shuffling train[0] =  971761970117357568 | After shuffling train[0] =  924442712396435456\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_ANTM_CI_target\n",
            "1. Type of train dataset\n",
            "Length of train: 19429\n",
            "Downloading: 100% 558/558 [00:00<00:00, 491kB/s]\n",
            "Downloading: 100% 843k/843k [00:00<00:00, 1.14MB/s]\n",
            "Downloading: 100% 1.08M/1.08M [00:01<00:00, 988kB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1215  | num_data= 19429\n",
            "97\n",
            "Eval_dataset: num_batches= 621  | num_data= 9927\n",
            "97\n",
            "Dataset created\n",
            "Mon Apr 11 04:25:52 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    57W / 149W |    345MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Downloading: 100% 543M/543M [00:12<00:00, 43.7MB/s]\n",
            "Model created\n",
            "Mon Apr 11 04:26:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    58W / 149W |    345MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 21.968549728393555\n",
            "Train loss at 100: 17.988534927368164\n",
            "Train loss at 200: 16.0981502532959\n",
            "Train loss at 300: 12.646259307861328\n",
            "Train loss at 400: 10.998578071594238\n",
            "Train loss at 500: 10.960247039794922\n",
            "Train loss at 600: 10.733620643615723\n",
            "Train loss at 700: 9.124942779541016\n",
            "Train loss at 800: 8.556650161743164\n",
            "Train loss at 900: 12.266667366027832\n",
            "Train loss at 1000: 13.238704681396484\n",
            "Train loss at 1100: 10.843195915222168\n",
            "Train loss at 1200: 10.61973762512207\n",
            "EVALUATING:\n",
            "Valid_loss 9.538009714965083\n",
            "[[2429  117  169   96]\n",
            " [ 503 3757  161   23]\n",
            " [ 245   35  586   15]\n",
            " [ 649   50   92 1000]]\n",
            "comment F1-score: 0.7319572095826428\n",
            "unrelated F1-score: 0.894204450791384\n",
            "support F1-score: 0.6204340921122288\n",
            "refute F1-score: 0.6837606837606838\n",
            "Accu: 0.7829152815553541\n",
            "F1-Weighted 0.7859971910164176\n",
            "F1-Avg 0.7325891090617349\n",
            "[0/5]     train_loss: 11.62954 valid_loss: 9.53801\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 5.6968255043029785\n",
            "Train loss at 100: 10.014242172241211\n",
            "Train loss at 200: 6.664062023162842\n",
            "Train loss at 300: 9.598482131958008\n",
            "Train loss at 400: 9.761244773864746\n",
            "Train loss at 500: 6.406624794006348\n",
            "Train loss at 600: 7.912357330322266\n",
            "Train loss at 700: 7.987180233001709\n",
            "Train loss at 800: 7.450157165527344\n",
            "Train loss at 900: 8.872273445129395\n",
            "Train loss at 1000: 11.359447479248047\n",
            "Train loss at 1100: 10.172201156616211\n",
            "Train loss at 1200: 6.1091413497924805\n",
            "EVALUATING:\n",
            "Valid_loss 8.8037821209949\n",
            "[[2283  101  204  223]\n",
            " [ 437 3828  154   25]\n",
            " [ 176   32  656   17]\n",
            " [ 445   54  115 1177]]\n",
            "comment F1-score: 0.7421976592977894\n",
            "unrelated F1-score: 0.905071521456437\n",
            "support F1-score: 0.6527363184079602\n",
            "refute F1-score: 0.7281163006495515\n",
            "Accu: 0.8002417648836506\n",
            "F1-Weighted 0.8046310519410952\n",
            "F1-Avg 0.7570304499529346\n",
            "[1/5]     train_loss: 7.94624 valid_loss: 8.80378\n",
            "\n",
            "\n",
            "========= Beginning 3 epoch ==========\n",
            "Train loss at 0: 3.016242027282715\n",
            "Train loss at 100: 8.35844612121582\n",
            "Train loss at 200: 6.020218849182129\n",
            "Train loss at 300: 8.434200286865234\n",
            "Train loss at 400: 8.974241256713867\n",
            "Train loss at 500: 6.624673366546631\n",
            "Train loss at 600: 7.345584869384766\n",
            "Train loss at 700: 3.6045949459075928\n",
            "Train loss at 800: 5.76759672164917\n",
            "Train loss at 900: 8.023283004760742\n",
            "Train loss at 1000: 8.610357284545898\n",
            "Train loss at 1100: 9.063457489013672\n",
            "Train loss at 1200: 5.9706268310546875\n",
            "EVALUATING:\n",
            "Valid_loss 9.319109045940897\n",
            "[[2223  111  208  269]\n",
            " [ 511 3755  147   31]\n",
            " [ 167   48  645   21]\n",
            " [ 390   66  102 1233]]\n",
            "comment F1-score: 0.7286135693215339\n",
            "unrelated F1-score: 0.8915004748338081\n",
            "support F1-score: 0.6505295007564296\n",
            "refute F1-score: 0.7372197309417039\n",
            "Accu: 0.7913770524831268\n",
            "F1-Weighted 0.7961557249730312\n",
            "F1-Avg 0.7519658189633689\n",
            "[2/5]     train_loss: 6.56741 valid_loss: 9.31911\n",
            "\n",
            "\n",
            "========= Beginning 4 epoch ==========\n",
            "Train loss at 0: 1.9452683925628662\n",
            "Train loss at 100: 5.846444129943848\n",
            "Train loss at 200: 5.590179920196533\n",
            "Train loss at 300: 5.4579339027404785\n",
            "Train loss at 400: 6.200810432434082\n",
            "Train loss at 500: 4.6243791580200195\n",
            "Train loss at 600: 6.343453407287598\n",
            "Train loss at 700: 3.501875400543213\n",
            "Train loss at 800: 8.575790405273438\n",
            "Train loss at 900: 5.913422584533691\n",
            "Train loss at 1000: 6.701080322265625\n",
            "Train loss at 1100: 6.4367899894714355\n",
            "Train loss at 1200: 5.152899742126465\n",
            "EVALUATING:\n",
            "Valid_loss 10.179471736560888\n",
            "[[2379  124  168  140]\n",
            " [ 486 3799  139   20]\n",
            " [ 195   35  641   10]\n",
            " [ 509   85  115 1082]]\n",
            "comment F1-score: 0.7457680250783699\n",
            "unrelated F1-score: 0.8952515612112644\n",
            "support F1-score: 0.6594650205761317\n",
            "refute F1-score: 0.7111403220506078\n",
            "Accu: 0.7959101440515766\n",
            "F1-Weighted 0.7987803824356168\n",
            "F1-Avg 0.7529062322290934\n",
            "[3/5]     train_loss: 5.54779 valid_loss: 10.17947\n",
            "\n",
            "\n",
            "========= Beginning 5 epoch ==========\n",
            "Train loss at 0: 1.352661371231079\n",
            "Train loss at 100: 5.001396656036377\n",
            "Train loss at 200: 5.466183185577393\n",
            "Train loss at 300: 3.94614315032959\n",
            "Train loss at 400: 4.669455528259277\n",
            "Train loss at 500: 2.4253897666931152\n",
            "Train loss at 600: 3.1620726585388184\n",
            "Train loss at 700: 2.894116163253784\n",
            "Train loss at 800: 5.140072345733643\n",
            "Train loss at 900: 4.849890232086182\n",
            "Train loss at 1000: 10.38275146484375\n",
            "Train loss at 1100: 4.573169708251953\n",
            "Train loss at 1200: 2.766753911972046\n",
            "EVALUATING:\n",
            "Valid_loss 10.602822135612008\n",
            "[[2251  109  211  240]\n",
            " [ 479 3756  173   36]\n",
            " [ 169   31  665   16]\n",
            " [ 406   51  129 1205]]\n",
            "comment F1-score: 0.7361020274689339\n",
            "unrelated F1-score: 0.895244905255631\n",
            "support F1-score: 0.6459446333171442\n",
            "refute F1-score: 0.7329683698296838\n",
            "Accu: 0.79349249521507\n",
            "F1-Weighted 0.7987785565113897\n",
            "F1-Avg 0.7525649839678482\n",
            "[4/5]     train_loss: 4.69901 valid_loss: 10.60282\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_ANTM_CI_target\n",
            "Total time taken (mins):  43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='ANTM_CI' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=2 --lr=1e-5 --notarget\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbN-00J7PXem",
        "outputId": "4911291e-959f-4217-88a0-fdcabd1e9705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = False\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 19429 0 9927\n",
            "Length of train, eval_set: 19429 9927\n",
            "Before shuffling train[0] =  971761970117357568 | After shuffling train[0] =  924442712396435456\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_ANTM_CI_notarget\n",
            "1. Type of train dataset\n",
            "Length of train: 19429\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1215  | num_data= 19429\n",
            "91\n",
            "Eval_dataset: num_batches= 621  | num_data= 9927\n",
            "91\n",
            "Dataset created\n",
            "Mon Apr 11 05:09:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0    68W / 149W |    343MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Model created\n",
            "Mon Apr 11 05:09:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0    68W / 149W |    343MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 21.830486297607422\n",
            "Train loss at 100: 18.265981674194336\n",
            "Train loss at 200: 14.986323356628418\n",
            "Train loss at 300: 13.157854080200195\n",
            "Train loss at 400: 13.03705883026123\n",
            "Train loss at 500: 13.251485824584961\n",
            "Train loss at 600: 9.281547546386719\n",
            "Train loss at 700: 10.282085418701172\n",
            "Train loss at 800: 9.815616607666016\n",
            "Train loss at 900: 10.32467269897461\n",
            "Train loss at 1000: 9.959009170532227\n",
            "Train loss at 1100: 9.370899200439453\n",
            "Train loss at 1200: 11.548888206481934\n",
            "EVALUATING:\n",
            "Valid_loss 9.446725263111833\n",
            "[[2361  122  203  125]\n",
            " [ 469 3810  139   26]\n",
            " [ 194   33  640   14]\n",
            " [ 606   33  147 1005]]\n",
            "comment F1-score: 0.7331159757801583\n",
            "unrelated F1-score: 0.9026297085998579\n",
            "support F1-score: 0.6368159203980099\n",
            "refute F1-score: 0.6788247213779128\n",
            "Accu: 0.787347637755616\n",
            "F1-Weighted 0.7906603540640961\n",
            "F1-Avg 0.7378465815389847\n",
            "[0/2]     train_loss: 11.74819 valid_loss: 9.44673\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 5.3058366775512695\n",
            "Train loss at 100: 9.50206184387207\n",
            "Train loss at 200: 7.038623809814453\n",
            "Train loss at 300: 7.9882354736328125\n",
            "Train loss at 400: 11.267891883850098\n",
            "Train loss at 500: 8.514158248901367\n",
            "Train loss at 600: 5.854304313659668\n",
            "Train loss at 700: 5.692763328552246\n",
            "Train loss at 800: 7.252315044403076\n",
            "Train loss at 900: 8.595505714416504\n",
            "Train loss at 1000: 8.714771270751953\n",
            "Train loss at 1100: 7.024633407592773\n",
            "Train loss at 1200: 8.520612716674805\n",
            "EVALUATING:\n",
            "Valid_loss 8.614719714135555\n",
            "[[2388  142  141  140]\n",
            " [ 391 3928   98   27]\n",
            " [ 215   53  595   18]\n",
            " [ 564   60   82 1085]]\n",
            "comment F1-score: 0.7498822421102215\n",
            "unrelated F1-score: 0.9106294192650979\n",
            "support F1-score: 0.6622148024485253\n",
            "refute F1-score: 0.7089186540346292\n",
            "Accu: 0.8054800040294148\n",
            "F1-Weighted 0.8066727784949228\n",
            "F1-Avg 0.7579112794646184\n",
            "[1/2]     train_loss: 8.16936 valid_loss: 8.61472\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_ANTM_CI_notarget\n",
            "Total time taken (mins):  16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AET_HUM"
      ],
      "metadata": {
        "id": "YCvArUEapJ8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# target\n",
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='AET_HUM' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=2 --lr=1e-5\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99YZ8Wln8R9a",
        "outputId": "e8dd1ed2-9a32-45ba-953a-aa3e0f3d2e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = True\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 22360 0 6996\n",
            "Length of train, eval_set: 22360 6996\n",
            "Before shuffling train[0] =  971761970117357568 | After shuffling train[0] =  861275445450244097\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_AET_HUM_target\n",
            "1. Type of train dataset\n",
            "Length of train: 22360\n",
            "Downloading: 100% 558/558 [00:00<00:00, 561kB/s]\n",
            "Downloading: 100% 843k/843k [00:00<00:00, 2.04MB/s]\n",
            "Downloading: 100% 1.08M/1.08M [00:00<00:00, 2.20MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1398  | num_data= 22360\n",
            "97\n",
            "Eval_dataset: num_batches= 438  | num_data= 6996\n",
            "97\n",
            "Dataset created\n",
            "Mon Apr 11 00:13:34 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    57W / 149W |    347MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Downloading: 100% 543M/543M [00:15<00:00, 35.8MB/s]\n",
            "Model created\n",
            "Mon Apr 11 00:13:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    57W / 149W |    347MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 21.99962043762207\n",
            "Train loss at 100: 16.786788940429688\n",
            "Train loss at 200: 13.03991985321045\n",
            "Train loss at 300: 6.862030506134033\n",
            "Train loss at 400: 8.999654769897461\n",
            "Train loss at 500: 11.596370697021484\n",
            "Train loss at 600: 6.639548301696777\n",
            "Train loss at 700: 7.751112937927246\n",
            "Train loss at 800: 12.330621719360352\n",
            "Train loss at 900: 9.406332015991211\n",
            "Train loss at 1000: 9.110044479370117\n",
            "Train loss at 1100: 4.168920993804932\n",
            "Train loss at 1200: 13.6277437210083\n",
            "Train loss at 1300: 5.653741836547852\n",
            "EVALUATING:\n",
            "Valid_loss 9.867584053512033\n",
            "[[1957  387  116   78]\n",
            " [ 291 2169   48   15]\n",
            " [ 193   72  645   27]\n",
            " [ 294   48   23  633]]\n",
            "comment F1-score: 0.742271951450787\n",
            "unrelated F1-score: 0.8343912290825158\n",
            "support F1-score: 0.7292255511588468\n",
            "refute F1-score: 0.7230154197601371\n",
            "Accu: 0.7724413950829045\n",
            "F1-Weighted 0.7709990014456463\n",
            "F1-Avg 0.7572260378630717\n",
            "[0/2]     train_loss: 10.55818 valid_loss: 9.86758\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 10.187602043151855\n",
            "Train loss at 100: 8.130061149597168\n",
            "Train loss at 200: 4.136658668518066\n",
            "Train loss at 300: 5.208573818206787\n",
            "Train loss at 400: 6.710473537445068\n",
            "Train loss at 500: 13.677225112915039\n",
            "Train loss at 600: 5.927854537963867\n",
            "Train loss at 700: 4.632608413696289\n",
            "Train loss at 800: 12.819700241088867\n",
            "Train loss at 900: 8.87980842590332\n",
            "Train loss at 1000: 6.17559814453125\n",
            "Train loss at 1100: 3.49312424659729\n",
            "Train loss at 1200: 12.427629470825195\n",
            "Train loss at 1300: 2.910985231399536\n",
            "EVALUATING:\n",
            "Valid_loss 9.559376674155667\n",
            "[[2050  274  120   94]\n",
            " [ 330 2116   62   15]\n",
            " [ 192   45  666   34]\n",
            " [ 276   36   19  667]]\n",
            "comment F1-score: 0.7612328258447828\n",
            "unrelated F1-score: 0.8474169002803364\n",
            "support F1-score: 0.738359201773836\n",
            "refute F1-score: 0.7378318584070795\n",
            "Accu: 0.7860205831903945\n",
            "F1-Weighted 0.7859120237498138\n",
            "F1-Avg 0.7712101965765087\n",
            "[1/2]     train_loss: 7.23091 valid_loss: 9.55938\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_AET_HUM_target\n",
            "Total time taken (mins):  19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# notarget\n",
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='AET_HUM' --test_mode=True --bert_type=vinai/bertweet-base --batch_size=16 --n_epochs=2 --lr=1e-5 --notarget\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn6YysTbG1XU",
        "outputId": "b39bb607-336f-4ea5-c9ad-eb5bf27be22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = False\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 22360 0 6996\n",
            "Length of train, eval_set: 22360 6996\n",
            "Before shuffling train[0] =  971761970117357568 | After shuffling train[0] =  861275445450244097\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_AET_HUM_notarget\n",
            "1. Type of train dataset\n",
            "Length of train: 22360\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1398  | num_data= 22360\n",
            "91\n",
            "Eval_dataset: num_batches= 438  | num_data= 6996\n",
            "91\n",
            "Dataset created\n",
            "Mon Apr 11 00:53:16 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    58W / 149W |    343MiB / 11441MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Model created\n",
            "Mon Apr 11 00:53:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    58W / 149W |    343MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 22.05508804321289\n",
            "Train loss at 100: 16.402254104614258\n",
            "Train loss at 200: 11.424614906311035\n",
            "Train loss at 300: 8.050885200500488\n",
            "Train loss at 400: 8.41867733001709\n",
            "Train loss at 500: 11.696306228637695\n",
            "Train loss at 600: 8.612150192260742\n",
            "Train loss at 700: 6.233981132507324\n",
            "Train loss at 800: 11.865645408630371\n",
            "Train loss at 900: 9.586726188659668\n",
            "Train loss at 1000: 7.850341796875\n",
            "Train loss at 1100: 3.3017594814300537\n",
            "Train loss at 1200: 14.581140518188477\n",
            "Train loss at 1300: 6.142574787139893\n",
            "EVALUATING:\n",
            "Valid_loss 10.238863862540624\n",
            "[[1898  400  169   71]\n",
            " [ 279 2171   61   12]\n",
            " [ 166   89  659   23]\n",
            " [ 305   55   35  603]]\n",
            "comment F1-score: 0.7319706903200925\n",
            "unrelated F1-score: 0.8289423444062619\n",
            "support F1-score: 0.708221386351424\n",
            "refute F1-score: 0.7065026362038664\n",
            "Accu: 0.7620068610634648\n",
            "F1-Weighted 0.7601281041898423\n",
            "F1-Avg 0.7439092643204112\n",
            "[0/2]     train_loss: 10.45448 valid_loss: 10.23886\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 10.57999038696289\n",
            "Train loss at 100: 9.589251518249512\n",
            "Train loss at 200: 3.695700168609619\n",
            "Train loss at 300: 4.036079406738281\n",
            "Train loss at 400: 6.618494033813477\n",
            "Train loss at 500: 12.464380264282227\n",
            "Train loss at 600: 5.544520378112793\n",
            "Train loss at 700: 5.6357855796813965\n",
            "Train loss at 800: 12.727762222290039\n",
            "Train loss at 900: 10.79049015045166\n",
            "Train loss at 1000: 5.349467754364014\n",
            "Train loss at 1100: 2.350886106491089\n",
            "Train loss at 1200: 9.664173126220703\n",
            "Train loss at 1300: 3.3090622425079346\n",
            "EVALUATING:\n",
            "Valid_loss 10.103350163322606\n",
            "[[1922  381  115  120]\n",
            " [ 285 2188   32   18]\n",
            " [ 169  136  592   40]\n",
            " [ 225   41   25  707]]\n",
            "comment F1-score: 0.7480054485308426\n",
            "unrelated F1-score: 0.8305181248813817\n",
            "support F1-score: 0.696061140505585\n",
            "refute F1-score: 0.7509293680297399\n",
            "Accu: 0.7731560891938251\n",
            "F1-Weighted 0.7712223921375669\n",
            "F1-Avg 0.7563785204868873\n",
            "[1/2]     train_loss: 7.25467 valid_loss: 10.10335\n",
            "/content/gdrive/.shortcut-targets-by-id/1EfEUYvABxjeNO888ZJWSNM5fn97YqKQr/NLP Stance Detection/Code_Kaushal/saves/wtwt_AET_HUM_notarget\n",
            "Total time taken (mins):  17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ci-ESRX"
      ],
      "metadata": {
        "id": "SNe79jOJ8S5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "!python gdrive/My\\ Drive/NLP\\ Stance\\ Detection/Code_Kaushal/train.py --dataset_name=wtwt --target_merger='CI_ESRX' --test_mode=True --bert_type=vinai/bertweet-base\n",
        "print('Total time taken (mins): ', int((time.time()-start_time)/60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coJJ1POg9faC",
        "outputId": "71f88c18-5873-4b8c-8056-c26006d8832d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++\n",
            "Target = True\n",
            "++++++++++++++++++++++\n",
            "{'comment': 0, 'unrelated': 1, 'support': 2, 'refute': 3} || {0: 'comment', 1: 'unrelated', 2: 'support', 3: 'refute'}\n",
            "Length of train, valid, test: 27130 0 2226\n",
            "Length of train, eval_set: 27130 2226\n",
            "Before shuffling train[0] =  944165633889095681 | After shuffling train[0] =  831878268378816513\n",
            "/content/gdrive/My Drive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CI_ESRX_target\n",
            "1. Type of train dataset\n",
            "Length of train: 27130\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Loaded Bert Tokenizer\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Train_dataset: num_batches= 1696  | num_data= 27130\n",
            "97\n",
            "Eval_dataset: num_batches= 140  | num_data= 2226\n",
            "97\n",
            "Dataset created\n",
            "Sun Apr 10 06:17:51 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    57W / 149W |    347MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Model created\n",
            "Sun Apr 10 06:17:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    57W / 149W |    347MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Embedding Shape: torch.Size([64004, 768])\n",
            "134905348\n",
            "Detected 1 GPUs!\n",
            "\n",
            "\n",
            "========= Beginning 1 epoch ==========\n",
            "Train loss at 0: 22.219301223754883\n",
            "Train loss at 100: 10.87669849395752\n",
            "Train loss at 200: 11.60993480682373\n",
            "Train loss at 300: 6.6688408851623535\n",
            "Train loss at 400: 9.261723518371582\n",
            "Train loss at 500: 13.811444282531738\n",
            "Train loss at 600: 4.690306663513184\n",
            "Train loss at 700: 8.1101655960083\n",
            "Train loss at 800: 7.552820205688477\n",
            "Train loss at 900: 9.698983192443848\n",
            "Train loss at 1000: 15.572582244873047\n",
            "Train loss at 1100: 4.982302665710449\n",
            "Train loss at 1200: 7.189706325531006\n",
            "Train loss at 1300: 8.597211837768555\n",
            "Train loss at 1400: 9.48330307006836\n",
            "Train loss at 1500: 12.561429023742676\n",
            "Train loss at 1600: 11.438940048217773\n",
            "EVALUATING:\n",
            "Valid_loss 15.170145138672419\n",
            "[[557 196  76  23]\n",
            " [ 58 342  31  30]\n",
            " [131  76 459  22]\n",
            " [104  18   7  96]]\n",
            "comment F1-score: 0.654524089306698\n",
            "unrelated F1-score: 0.62580054894785\n",
            "support F1-score: 0.7279936558287075\n",
            "refute F1-score: 0.48484848484848486\n",
            "Accu: 0.6531895777178796\n",
            "F1-Weighted 0.6541325792701371\n",
            "F1-Avg 0.6232916947329351\n",
            "[0/5]     train_loss: 10.53912 valid_loss: 15.17015\n",
            "\n",
            "\n",
            "========= Beginning 2 epoch ==========\n",
            "Train loss at 0: 6.60715389251709\n",
            "Train loss at 100: 11.857746124267578\n",
            "Train loss at 200: 7.668467044830322\n",
            "Train loss at 300: 6.954254150390625\n",
            "Train loss at 400: 7.7393598556518555\n",
            "Train loss at 500: 11.906694412231445\n",
            "Train loss at 600: 2.3042116165161133\n",
            "Train loss at 800: 7.630862236022949\n",
            "Train loss at 900: 6.4146647453308105\n",
            "Train loss at 1000: 14.727062225341797\n",
            "Train loss at 1100: 4.864998817443848\n",
            "Train loss at 1200: 7.378816604614258\n",
            "Train loss at 1300: 4.5424604415893555\n",
            "Train loss at 1400: 8.478086471557617\n",
            "Train loss at 1500: 22.770631790161133\n",
            "Train loss at 1600: 21.429107666015625\n",
            "EVALUATING:\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Valid_loss 21.282231981413705\n",
            "[[  0 852   0   0]\n",
            " [  0 461   0   0]\n",
            " [  0 688   0   0]\n",
            " [  0 225   0   0]]\n",
            "comment F1-score: 0.0\n",
            "unrelated F1-score: 0.34313360625232603\n",
            "support F1-score: 0.0\n",
            "refute F1-score: 0.0\n",
            "Accu: 0.20709793351302785\n",
            "F1-Weighted 0.0710622607737297\n",
            "F1-Avg 0.08578340156308151\n",
            "[1/5]     train_loss: 9.78427 valid_loss: 21.28223\n",
            "\n",
            "\n",
            "========= Beginning 3 epoch ==========\n",
            "Train loss at 0: 22.277503967285156\n",
            "Train loss at 100: 20.360586166381836\n",
            "Train loss at 200: 19.356407165527344\n",
            "Train loss at 300: 19.655851364135742\n",
            "Train loss at 400: 20.368183135986328\n",
            "Train loss at 500: 21.34236717224121\n",
            "Train loss at 600: 18.72800636291504\n",
            "Train loss at 700: 16.439138412475586\n",
            "Train loss at 800: 24.056461334228516\n",
            "Train loss at 900: 18.8583927154541\n",
            "Train loss at 1000: 22.27682113647461\n",
            "Train loss at 1100: 18.787982940673828\n",
            "Train loss at 1200: 20.46442413330078\n",
            "Train loss at 1300: 20.29852867126465\n",
            "Train loss at 1400: 21.75789451599121\n",
            "Train loss at 1500: 20.149263381958008\n",
            "Train loss at 1600: 21.20758819580078\n",
            "EVALUATING:\n",
            "Valid_loss 21.12981834071023\n",
            "[[852   0   0   0]\n",
            " [461   0   0   0]\n",
            " [688   0   0   0]\n",
            " [225   0   0   0]]\n",
            "comment F1-score: 0.5536062378167641\n",
            "unrelated F1-score: 0.0\n",
            "support F1-score: 0.0\n",
            "refute F1-score: 0.0\n",
            "Accu: 0.38274932614555257\n",
            "F1-Weighted 0.21189241447434098\n",
            "F1-Avg 0.13840155945419103\n",
            "[2/5]     train_loss: 20.49398 valid_loss: 21.12982\n",
            "\n",
            "\n",
            "========= Beginning 4 epoch ==========\n",
            "Train loss at 0: 21.997325897216797\n",
            "Train loss at 100: 21.006603240966797\n",
            "Train loss at 200: 18.725831985473633\n",
            "Train loss at 300: 18.18463897705078\n",
            "Train loss at 400: 20.23356819152832\n",
            "Train loss at 500: 21.06370735168457\n",
            "Train loss at 600: 18.410757064819336\n",
            "Train loss at 700: 16.832382202148438\n",
            "Train loss at 800: 24.394758224487305\n",
            "Train loss at 900: 18.849924087524414\n",
            "Train loss at 1000: 22.860031127929688\n",
            "Train loss at 1100: 18.626768112182617\n",
            "Train loss at 1200: 20.219083786010742\n",
            "Train loss at 1300: 20.1392822265625\n",
            "Train loss at 1400: 21.698965072631836\n",
            "Train loss at 1500: 20.16417694091797\n",
            "Train loss at 1600: 21.337841033935547\n",
            "EVALUATING:\n",
            "Valid_loss 21.464442685672214\n",
            "[[852   0   0   0]\n",
            " [461   0   0   0]\n",
            " [688   0   0   0]\n",
            " [225   0   0   0]]\n",
            "comment F1-score: 0.5536062378167641\n",
            "unrelated F1-score: 0.0\n",
            "support F1-score: 0.0\n",
            "refute F1-score: 0.0\n",
            "Accu: 0.38274932614555257\n",
            "F1-Weighted 0.21189241447434098\n",
            "F1-Avg 0.13840155945419103\n",
            "[3/5]     train_loss: 20.42704 valid_loss: 21.46444\n",
            "\n",
            "\n",
            "========= Beginning 5 epoch ==========\n",
            "Train loss at 0: 21.902284622192383\n",
            "Train loss at 100: 20.97664451599121\n",
            "Train loss at 200: 18.978919982910156\n",
            "Train loss at 300: 18.251052856445312\n",
            "Train loss at 400: 20.323036193847656\n",
            "Train loss at 500: 21.095996856689453\n",
            "Train loss at 600: 18.192642211914062\n",
            "Train loss at 700: 16.837453842163086\n",
            "Train loss at 800: 24.188457489013672\n",
            "Train loss at 900: 18.907283782958984\n",
            "Train loss at 1000: 22.753665924072266\n",
            "Train loss at 1100: 18.578643798828125\n",
            "Train loss at 1200: 20.444501876831055\n",
            "Train loss at 1300: 20.29966926574707\n",
            "Train loss at 1400: 21.571943283081055\n",
            "Train loss at 1500: 20.230297088623047\n",
            "Train loss at 1600: 21.265506744384766\n",
            "EVALUATING:\n",
            "Valid_loss 21.65709913798741\n",
            "[[852   0   0   0]\n",
            " [461   0   0   0]\n",
            " [688   0   0   0]\n",
            " [225   0   0   0]]\n",
            "comment F1-score: 0.5536062378167641\n",
            "unrelated F1-score: 0.0\n",
            "support F1-score: 0.0\n",
            "refute F1-score: 0.0\n",
            "Accu: 0.38274932614555257\n",
            "F1-Weighted 0.21189241447434098\n",
            "F1-Avg 0.13840155945419103\n",
            "[4/5]     train_loss: 20.40804 valid_loss: 21.65710\n",
            "/content/gdrive/My Drive/NLP Stance Detection/Code_Kaushal/saves/wtwt_CI_ESRX_target\n",
            "Total time taken (mins):  50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SRxL7JWgHuWs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}